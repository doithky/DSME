{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3SMFJYftfEs"
   },
   "source": [
    "# 190. Keras API 와 LSTM 을 이용한 이상한 나라의 Alice 문장 생성기\n",
    "\n",
    "- next word 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asn1fHFytfEu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uP-mC7LTtfEx",
    "outputId": "65a1d1cc-1741-41a3-c309-2791df18a267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.gutenberg.org/files/11/11.txt\n",
      "172032/167546 [==============================] - 2s 12us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('alice.txt', \"http://www.gutenberg.org/files/11/11.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SvrmXp25tfEz",
    "outputId": "d1b28ce4-e7d2-4b08-9b25-8e5a2a54bd8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"project gutenberg's alice's adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alice's adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 [last updated: december 20, 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pi\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = open(path_to_file, 'r')\n",
    "texts = r.readlines()\n",
    "lines = []\n",
    "\n",
    "for line in texts:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RuGgWAmtfE2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = re.split('[,.]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "RyUJ7MxNtfE4",
    "outputId": "c391ab6c-73c1-4b84-a212-01ff4b225511"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"project gutenberg's alice's adventures in wonderland\",\n",
       " ' by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever',\n",
       " '  you may copy it',\n",
       " ' give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www',\n",
       " 'gutenberg',\n",
       " \"org title: alice's adventures in wonderland author: lewis carroll posting date: june 25\",\n",
       " ' 2008 [ebook #11] release date: march',\n",
       " ' 1994 [last updated: december 20',\n",
       " \" 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3\",\n",
       " '0 chapter i']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mRzxcEeatfE6",
    "outputId": "feab9894-d43c-4c89-a35d-a6579edf062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3338\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rD29b-YrM8hJ",
    "outputId": "4ec506f5-90e5-407b-a6fa-5896c36654a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'you'), (12, 'alice'), (13, 'was'), (14, 'i'), (15, 'that')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.index_word.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4UF7YzUM8hO",
    "outputId": "db1c688d-f1ef-45e8-a87c-e78f2eb8e75e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 11), ('alice', 12), ('was', 13), ('i', 14), ('that', 15)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.word_index.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQlBVvwitfE8"
   },
   "outputs": [],
   "source": [
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nI97Ln4atfE_",
    "outputId": "5c43d818-1bb4-4bbe-9a47-ae0649b6465f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[48, 1303],\n",
       " [48, 1303, 248],\n",
       " [48, 1303, 248, 342],\n",
       " [48, 1303, 248, 342, 10],\n",
       " [48, 1303, 248, 342, 10, 481],\n",
       " [59, 815],\n",
       " [59, 815, 816],\n",
       " [59, 815, 816, 22],\n",
       " [59, 815, 816, 22, 443],\n",
       " [59, 815, 816, 22, 443, 31]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_sequences))\n",
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "neKxP5KXtfFB",
    "outputId": "75f20215-eb80-4ffb-d445-9d4074369bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   48, 1303],\n",
       "       [   0,    0,    0, ...,   48, 1303,  248],\n",
       "       [   0,    0,    0, ..., 1303,  248,  342],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,  275,   40],\n",
       "       [   0,    0,    0, ...,  275,   40,  494],\n",
       "       [   0,    0,    0, ...,   40,  494,  621]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejnqC8LZtfFE"
   },
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02XRjp6htfFH"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[-1]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "CqJpy2c-tfFJ",
    "outputId": "4fbb4e71-60c2-4d76-bd1c-260e84112b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   0    0    0 ...    0    0   48]\n",
      " [   0    0    0 ...    0   48 1303]\n",
      " [   0    0    0 ...   48 1303  248]\n",
      " ...\n",
      " [   0    0    0 ...    8 1317    4]\n",
      " [   0    0    0 ... 1317    4   17]\n",
      " [   0    0    0 ...    4   17   15]], shape=(256, 62), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[1303  248  342   10  481  815  816   22  443   31   24    1  151    6\n",
      "  704 1006   19   49  817    3   18  482   49 1304 1305  175  343    8\n",
      "    8  169   27 1306  151    8  203    1  204    6    1   48   44  258\n",
      " 1007   18   22  443   27  818   19  625 1826  248  342   10  481 1827\n",
      "  815  816 1828  819 1829 1830  443  820 1832  819  136  140 1307 1834\n",
      " 1308 1836  550 1309  196 1837 1008 1009    6   22   48   44  443  248\n",
      "  342   10  481  248  342   10  481  815  816    1 1838 1839 1310  373\n",
      "  344   14    1  110  705   12   13  274    4  115   29  551    6  405\n",
      "   59   17  483   20    1 1010    6  406  154    4   45  148   27  706\n",
      "    7   23 1011   68    1  374   17  483   13  821    8   23   49  822\n",
      "   27 1311   10    8   38   31    1  151    6    5  374   62   12 1841\n",
      "  822   27 1311    2   28    7   13 1012   10   17  407  375   16  121\n",
      "   16    7   57    1  552  162  155   17  484   29  707    3 1013    1\n",
      " 1312    6  485    5 1842 1843   58   25  823    1  626    6  205   39\n",
      "    3 1313    1 1844  315    5  156  110   18 1845  163  259  316   59\n",
      "   17   13  154   28   29 1314   10   15 1315   74   12   91    8   28\n",
      "   29   93   35    6    1   76    4  275    1  110   95    4  295  170\n",
      "  206  170   14  188   25  627    2   60    7   62    8  122 1316 1317\n",
      "    4   17   15    7], shape=(256,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = text_dataset.map(split_input_target).batch(256, drop_remainder=True)\n",
    "\n",
    "for input, target in dataset.take(1):\n",
    "    print(input)\n",
    "    print()\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "w9vH8Y59ajYL",
    "outputId": "ce281ecb-c138-4427-ae07-7acb50ee446a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         333800    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 64)          34048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1669)              28373     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3338)              5574460   \n",
      "=================================================================\n",
      "Total params: 5,975,865\n",
      "Trainable params: 5,975,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AIg2f1HBxqof",
    "outputId": "1097eae8-3e42-4195-ccd1-6012ee2bee6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(dataset, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "1fXTEO3GJ282",
    "outputId": "da684fdf-ba96-4370-fb0f-1e38517622db"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9ddac66220d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MPTokoLYxCvI",
    "outputId": "5d023aa0-7e6e-41ff-e733-dde37d0d5f6e"
   },
   "outputs": [],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = tokenizer.index_word[predicted[0]]\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJzIYX4Fw574"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "190_Generating_LSTM_Sentences_AliceWonderland_next_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
