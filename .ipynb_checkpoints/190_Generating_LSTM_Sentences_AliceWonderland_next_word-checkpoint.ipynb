{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3SMFJYftfEs"
   },
   "source": [
    "# 190. Keras API 와 LSTM 을 이용한 이상한 나라의 Alice 문장 생성기\n",
    "\n",
    "- next word 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xQWk90P4thyK",
    "outputId": "5ee3a384-8bec-47fc-a2e8-2c7296b99139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asn1fHFytfEu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP-mC7LTtfEx"
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('alice.txt', \"http://www.gutenberg.org/files/11/11.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SvrmXp25tfEz",
    "outputId": "8c61ff3f-12b0-4d57-af7f-94aac4875641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"project gutenberg's alice's adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alice's adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 [last updated: december 20, 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pi\""
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = open(path_to_file)\n",
    "texts = r.readlines()\n",
    "lines = []\n",
    "\n",
    "for line in texts:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RuGgWAmtfE2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = re.split('[,.]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "RyUJ7MxNtfE4",
    "outputId": "f9af7cce-3241-40f6-ae33-1bd3ae640bf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"project gutenberg's alice's adventures in wonderland\",\n",
       " ' by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever',\n",
       " '  you may copy it',\n",
       " ' give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www',\n",
       " 'gutenberg',\n",
       " \"org title: alice's adventures in wonderland author: lewis carroll posting date: june 25\",\n",
       " ' 2008 [ebook #11] release date: march',\n",
       " ' 1994 [last updated: december 20',\n",
       " \" 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3\",\n",
       " '0 chapter i']"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mRzxcEeatfE6",
    "outputId": "f583d310-6e4c-4830-a655-1341fa1947cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3338\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rD29b-YrM8hJ",
    "outputId": "05857171-2834-4ef1-ba98-2a885b4802d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'you'), (12, 'alice'), (13, 'was'), (14, 'i'), (15, 'that')]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.index_word.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4UF7YzUM8hO",
    "outputId": "498f80da-0220-4ec2-ad87-e9dd2a51e132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 11), ('alice', 12), ('was', 13), ('i', 14), ('that', 15)]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.word_index.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQlBVvwitfE8"
   },
   "outputs": [],
   "source": [
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "nI97Ln4atfE_",
    "outputId": "42f02cb7-258d-4e50-8257-1cde57561a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[48, 1303],\n",
       " [48, 1303, 248],\n",
       " [48, 1303, 248, 342],\n",
       " [48, 1303, 248, 342, 10],\n",
       " [48, 1303, 248, 342, 10, 481],\n",
       " [59, 815],\n",
       " [59, 815, 816],\n",
       " [59, 815, 816, 22],\n",
       " [59, 815, 816, 22, 443],\n",
       " [59, 815, 816, 22, 443, 31]]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_sequences))\n",
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "neKxP5KXtfFB",
    "outputId": "559a7886-4f70-4772-e833-6001ad4ee809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   48, 1303],\n",
       "       [   0,    0,    0, ...,   48, 1303,  248],\n",
       "       [   0,    0,    0, ..., 1303,  248,  342],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,  275,   40],\n",
       "       [   0,    0,    0, ...,  275,   40,  494],\n",
       "       [   0,    0,    0, ...,   40,  494,  621]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejnqC8LZtfFE"
   },
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02XRjp6htfFH"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[-1]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "CqJpy2c-tfFJ",
    "outputId": "746a6bcc-9b4a-43e9-e1e5-7f167904275c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   0    0    0 ...    0    0   48]\n",
      " [   0    0    0 ...    0   48 1303]\n",
      " [   0    0    0 ...   48 1303  248]\n",
      " ...\n",
      " [   0    0    0 ...    8 1317    4]\n",
      " [   0    0    0 ... 1317    4   17]\n",
      " [   0    0    0 ...    4   17   15]], shape=(256, 62), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[1303  248  342   10  481  815  816   22  443   31   24    1  151    6\n",
      "  704 1006   19   49  817    3   18  482   49 1304 1305  175  343    8\n",
      "    8  169   27 1306  151    8  203    1  204    6    1   48   44  258\n",
      " 1007   18   22  443   27  818   19  625 1826  248  342   10  481 1827\n",
      "  815  816 1828  819 1829 1830  443  820 1832  819  136  140 1307 1834\n",
      " 1308 1836  550 1309  196 1837 1008 1009    6   22   48   44  443  248\n",
      "  342   10  481  248  342   10  481  815  816    1 1838 1839 1310  373\n",
      "  344   14    1  110  705   12   13  274    4  115   29  551    6  405\n",
      "   59   17  483   20    1 1010    6  406  154    4   45  148   27  706\n",
      "    7   23 1011   68    1  374   17  483   13  821    8   23   49  822\n",
      "   27 1311   10    8   38   31    1  151    6    5  374   62   12 1841\n",
      "  822   27 1311    2   28    7   13 1012   10   17  407  375   16  121\n",
      "   16    7   57    1  552  162  155   17  484   29  707    3 1013    1\n",
      " 1312    6  485    5 1842 1843   58   25  823    1  626    6  205   39\n",
      "    3 1313    1 1844  315    5  156  110   18 1845  163  259  316   59\n",
      "   17   13  154   28   29 1314   10   15 1315   74   12   91    8   28\n",
      "   29   93   35    6    1   76    4  275    1  110   95    4  295  170\n",
      "  206  170   14  188   25  627    2   60    7   62    8  122 1316 1317\n",
      "    4   17   15    7], shape=(256,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = text_dataset.map(split_input_target).batch(256, drop_remainder=True)\n",
    "\n",
    "for input, target in dataset.take(1):\n",
    "    print(input)\n",
    "    print()\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "w9vH8Y59ajYL",
    "outputId": "d5651ca3-b8b7-4091-ed98-ba7f911ba58e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         333800    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          34048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1669)              28373     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3338)              5574460   \n",
      "=================================================================\n",
      "Total params: 5,975,865\n",
      "Trainable params: 5,975,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AIg2f1HBxqof",
    "outputId": "ee2ef47f-1ee0-4a70-8624-0107b441eec2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 106 steps\n",
      "Epoch 1/150\n",
      "106/106 [==============================] - 6s 56ms/step - loss: 6.9080 - accuracy: 0.0617\n",
      "Epoch 2/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 6.2999 - accuracy: 0.0622\n",
      "Epoch 3/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 6.1775 - accuracy: 0.0622\n",
      "Epoch 4/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 6.1317 - accuracy: 0.0623\n",
      "Epoch 5/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 6.0576 - accuracy: 0.0660\n",
      "Epoch 6/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.9701 - accuracy: 0.0688\n",
      "Epoch 7/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.8958 - accuracy: 0.0737\n",
      "Epoch 8/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.8262 - accuracy: 0.0777\n",
      "Epoch 9/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.7446 - accuracy: 0.0846\n",
      "Epoch 10/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.6617 - accuracy: 0.0928\n",
      "Epoch 11/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.5839 - accuracy: 0.0992\n",
      "Epoch 12/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.5116 - accuracy: 0.1064\n",
      "Epoch 13/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.4397 - accuracy: 0.1110\n",
      "Epoch 14/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.3744 - accuracy: 0.1139\n",
      "Epoch 15/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.3144 - accuracy: 0.1177\n",
      "Epoch 16/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.2554 - accuracy: 0.1212\n",
      "Epoch 17/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.2029 - accuracy: 0.1255\n",
      "Epoch 18/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.1506 - accuracy: 0.1315\n",
      "Epoch 19/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 5.1036 - accuracy: 0.1348\n",
      "Epoch 20/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 5.0593 - accuracy: 0.1380\n",
      "Epoch 21/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 5.0155 - accuracy: 0.1423\n",
      "Epoch 22/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.9790 - accuracy: 0.1459\n",
      "Epoch 23/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.9434 - accuracy: 0.1470\n",
      "Epoch 24/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 4.9065 - accuracy: 0.1512\n",
      "Epoch 25/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.8673 - accuracy: 0.1540\n",
      "Epoch 26/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.8369 - accuracy: 0.1586\n",
      "Epoch 27/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.8096 - accuracy: 0.1582\n",
      "Epoch 28/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.7759 - accuracy: 0.1621\n",
      "Epoch 29/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.7460 - accuracy: 0.1638\n",
      "Epoch 30/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.7160 - accuracy: 0.1677\n",
      "Epoch 31/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.6864 - accuracy: 0.1695\n",
      "Epoch 32/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.6622 - accuracy: 0.1728\n",
      "Epoch 33/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.6368 - accuracy: 0.1741\n",
      "Epoch 34/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.6130 - accuracy: 0.1770\n",
      "Epoch 35/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.5843 - accuracy: 0.1797\n",
      "Epoch 36/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 4.5661 - accuracy: 0.1822\n",
      "Epoch 37/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.5402 - accuracy: 0.1848\n",
      "Epoch 38/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.5095 - accuracy: 0.1872\n",
      "Epoch 39/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.4873 - accuracy: 0.1900\n",
      "Epoch 40/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.4587 - accuracy: 0.1917\n",
      "Epoch 41/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.4337 - accuracy: 0.1942\n",
      "Epoch 42/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.4045 - accuracy: 0.1975\n",
      "Epoch 43/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 4.3792 - accuracy: 0.1995\n",
      "Epoch 44/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.3539 - accuracy: 0.2026\n",
      "Epoch 45/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.3289 - accuracy: 0.2037\n",
      "Epoch 46/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.3001 - accuracy: 0.2071\n",
      "Epoch 47/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.2757 - accuracy: 0.2101\n",
      "Epoch 48/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 4.2595 - accuracy: 0.2126\n",
      "Epoch 49/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.2259 - accuracy: 0.2147\n",
      "Epoch 50/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 4.2119 - accuracy: 0.2152\n",
      "Epoch 51/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.1877 - accuracy: 0.2167\n",
      "Epoch 52/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.1690 - accuracy: 0.2174\n",
      "Epoch 53/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.1359 - accuracy: 0.2218\n",
      "Epoch 54/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.1138 - accuracy: 0.2258\n",
      "Epoch 55/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.0899 - accuracy: 0.2268\n",
      "Epoch 56/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.0749 - accuracy: 0.2292\n",
      "Epoch 57/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 4.0519 - accuracy: 0.2297\n",
      "Epoch 58/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.0310 - accuracy: 0.2343\n",
      "Epoch 59/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 4.0092 - accuracy: 0.2364\n",
      "Epoch 60/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.9901 - accuracy: 0.2374\n",
      "Epoch 61/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.9657 - accuracy: 0.2396\n",
      "Epoch 62/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.9511 - accuracy: 0.2424\n",
      "Epoch 63/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.9420 - accuracy: 0.2412\n",
      "Epoch 64/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.9448 - accuracy: 0.2401\n",
      "Epoch 65/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.9135 - accuracy: 0.2425\n",
      "Epoch 66/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.8792 - accuracy: 0.2465\n",
      "Epoch 67/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.8545 - accuracy: 0.2505\n",
      "Epoch 68/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.8526 - accuracy: 0.2536\n",
      "Epoch 69/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.8270 - accuracy: 0.2547\n",
      "Epoch 70/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.8149 - accuracy: 0.2562\n",
      "Epoch 71/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.7956 - accuracy: 0.2578\n",
      "Epoch 72/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.7740 - accuracy: 0.2581\n",
      "Epoch 73/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.7588 - accuracy: 0.2621\n",
      "Epoch 74/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.7389 - accuracy: 0.2654\n",
      "Epoch 75/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.7268 - accuracy: 0.2665\n",
      "Epoch 76/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.7085 - accuracy: 0.2654\n",
      "Epoch 77/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.6892 - accuracy: 0.2682\n",
      "Epoch 78/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.6775 - accuracy: 0.2729\n",
      "Epoch 79/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.6640 - accuracy: 0.2719\n",
      "Epoch 80/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.6481 - accuracy: 0.2762\n",
      "Epoch 81/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.6313 - accuracy: 0.2779\n",
      "Epoch 82/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.6168 - accuracy: 0.2773\n",
      "Epoch 83/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.6014 - accuracy: 0.2801\n",
      "Epoch 84/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.5866 - accuracy: 0.2832\n",
      "Epoch 85/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.5698 - accuracy: 0.2835\n",
      "Epoch 86/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.5626 - accuracy: 0.2851\n",
      "Epoch 87/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.5464 - accuracy: 0.2857\n",
      "Epoch 88/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.5372 - accuracy: 0.2879\n",
      "Epoch 89/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.5151 - accuracy: 0.2914\n",
      "Epoch 90/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.4967 - accuracy: 0.2934\n",
      "Epoch 91/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.4819 - accuracy: 0.2985\n",
      "Epoch 92/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.4698 - accuracy: 0.2981\n",
      "Epoch 93/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.4577 - accuracy: 0.2982\n",
      "Epoch 94/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 3.4525 - accuracy: 0.2997\n",
      "Epoch 95/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.4301 - accuracy: 0.2997\n",
      "Epoch 96/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.4366 - accuracy: 0.3007\n",
      "Epoch 97/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.4259 - accuracy: 0.3013\n",
      "Epoch 98/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 3.3987 - accuracy: 0.3067\n",
      "Epoch 99/150\n",
      "106/106 [==============================] - 4s 33ms/step - loss: 3.3813 - accuracy: 0.3094\n",
      "Epoch 100/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 3.3668 - accuracy: 0.3110\n",
      "Epoch 101/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.3602 - accuracy: 0.3139\n",
      "Epoch 102/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.3380 - accuracy: 0.3140\n",
      "Epoch 103/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.3329 - accuracy: 0.3129\n",
      "Epoch 104/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.3207 - accuracy: 0.3167\n",
      "Epoch 105/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.3070 - accuracy: 0.3181\n",
      "Epoch 106/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.2961 - accuracy: 0.3227\n",
      "Epoch 107/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.2818 - accuracy: 0.3259\n",
      "Epoch 108/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.2963 - accuracy: 0.3202\n",
      "Epoch 109/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 3.2800 - accuracy: 0.3220\n",
      "Epoch 110/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.2560 - accuracy: 0.3255\n",
      "Epoch 111/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.2406 - accuracy: 0.3285\n",
      "Epoch 112/150\n",
      "106/106 [==============================] - 4s 34ms/step - loss: 3.2394 - accuracy: 0.3275\n",
      "Epoch 113/150\n",
      "106/106 [==============================] - 4s 33ms/step - loss: 3.2173 - accuracy: 0.3321\n",
      "Epoch 114/150\n",
      "106/106 [==============================] - 4s 33ms/step - loss: 3.2025 - accuracy: 0.3332\n",
      "Epoch 115/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.1869 - accuracy: 0.3374\n",
      "Epoch 116/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 3.1659 - accuracy: 0.3433\n",
      "Epoch 117/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.1531 - accuracy: 0.3440\n",
      "Epoch 118/150\n",
      "106/106 [==============================] - 4s 34ms/step - loss: 3.1587 - accuracy: 0.3430\n",
      "Epoch 119/150\n",
      "106/106 [==============================] - 3s 33ms/step - loss: 3.1506 - accuracy: 0.3433\n",
      "Epoch 120/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.1365 - accuracy: 0.3456\n",
      "Epoch 121/150\n",
      "106/106 [==============================] - 4s 33ms/step - loss: 3.1143 - accuracy: 0.3485\n",
      "Epoch 122/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.1489 - accuracy: 0.3459\n",
      "Epoch 123/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.1115 - accuracy: 0.3485\n",
      "Epoch 124/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.0889 - accuracy: 0.3532\n",
      "Epoch 125/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.0815 - accuracy: 0.3552\n",
      "Epoch 126/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.0691 - accuracy: 0.3548\n",
      "Epoch 127/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.0519 - accuracy: 0.3624\n",
      "Epoch 128/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.0389 - accuracy: 0.3649\n",
      "Epoch 129/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 3.0375 - accuracy: 0.3642\n",
      "Epoch 130/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.0239 - accuracy: 0.3673\n",
      "Epoch 131/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 3.0087 - accuracy: 0.3704\n",
      "Epoch 132/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9979 - accuracy: 0.3703\n",
      "Epoch 133/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9878 - accuracy: 0.3708\n",
      "Epoch 134/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.9795 - accuracy: 0.3723\n",
      "Epoch 135/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9617 - accuracy: 0.3772\n",
      "Epoch 136/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.9514 - accuracy: 0.3781\n",
      "Epoch 137/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9428 - accuracy: 0.3798\n",
      "Epoch 138/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9389 - accuracy: 0.3809\n",
      "Epoch 139/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9193 - accuracy: 0.3831\n",
      "Epoch 140/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9285 - accuracy: 0.3844\n",
      "Epoch 141/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.9013 - accuracy: 0.3876\n",
      "Epoch 142/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.8923 - accuracy: 0.3898\n",
      "Epoch 143/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.8818 - accuracy: 0.3928\n",
      "Epoch 144/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.8816 - accuracy: 0.3944\n",
      "Epoch 145/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.8765 - accuracy: 0.3921\n",
      "Epoch 146/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.8687 - accuracy: 0.3930\n",
      "Epoch 147/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.8626 - accuracy: 0.3966\n",
      "Epoch 148/150\n",
      "106/106 [==============================] - 3s 31ms/step - loss: 2.8652 - accuracy: 0.3943\n",
      "Epoch 149/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.8380 - accuracy: 0.3995\n",
      "Epoch 150/150\n",
      "106/106 [==============================] - 3s 32ms/step - loss: 2.8301 - accuracy: 0.4003\n",
      "CPU times: user 9min 18s, sys: 57.1 s, total: 10min 15s\n",
      "Wall time: 8min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(dataset, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "1fXTEO3GJ282",
    "outputId": "951b05d4-7648-44e9-8091-2b517a3f016f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAEICAYAAACtaWlhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZzW8/rH8delXdJCi0oLJUpazCmd\nbIkUKecIcUK2LGWt04KfyC46xckSpwhJ9hAOiU6WalKhkpKohFFpo2Xq+v3x+cbdaGpq7pnvPTPv\n5+NxP+a+v8t9X1N8u+7P9/pcH3N3RERERETkD3vFHYCIiIiISKpRkiwiIiIikoWSZBERERGRLJQk\ni4iIiIhkoSRZRERERCQLJckiIiIiIlkoSZZ8Y2bFzGydmdVK5rEiIpJ6UuWab2a3m9kTyX5fKfyK\nxx2ApC4zW5fwcm9gI7Alen2Zuz+zO+/n7luAfZJ9rIiI5J6u+SLbU5Is2XL33y9YZrYYuMTd383u\neDMr7u6Z+RFbQaY/JxFJRbrmi2xP5Rayx6JbWM+Z2bNmthboZmatzOwTM/vFzJab2QNmViI6vriZ\nuZnViV4/He1/08zWmtnHZlZ3d4+N9ncws6/MbLWZPWhmH5pZ92zizjbGaH9jM3vXzFaa2Q9m1jch\npv8zs6/NbI2ZpZtZdTOrZ2ae5TOmbPt8M7vEzCZHn7MSuMnM6pvZpOgzfjazp8ysfML5tc3sFTPL\niPYPM7PSUcyHJRx3gJn9amb77fnfpIjIrhXUa/4Ofo+/mdmcKOb3zKxBwr4bzOz76Br/pZkdH20/\nysw+jbb/aGaDk/BHKilOSbLk1t+AMUB54DkgE7gG2B9oDbQHLtvJ+ecC/wdUAr4DbtvdY82sCjAO\n+Gf0ud8ALXbyPtnGGCWq7wKvAQcAhwDvR+f9E+gSHV8BuATYsJPPSfRXYB5QGbgHMOB2oBrQEDgo\n+t0ws+LAG8BCoA5wIDDO3TdEv2e3LH8mb7v7ihzGISKSGwXxmv+7aJDhKeAqwvX4XWC8mZUws0ZR\n7M3dfV+gQ/S5AA8Cg6Pt9YAXcvJ5UrApSZbcmuLur7n7Vnf/zd2nu/tUd89090XACOC4nZz/grun\nu/tm4Bmg6R4c2xGY5e6vRvv+Bfyc3ZvsIsZOwHfuPszdN7r7GnefFu27BLjB3RdEv+8sd1+58z+e\n333n7g+7+5boz+krd5/o7pvc/aco5m0xtCJc+Pu5+/ro+A+jfU8C55qZRa/PI1zwRUTyQ4G75mfR\nFRjv7u9F595NSPhbEhL+0kAjC6Uk30S/E8BmoL6Z7efua919ag4/TwowJcmSW0sSX5jZoWb2RlSm\nsAYYREj4svNDwvNf2fnEjeyOrZ4Yh7s7sDS7N9lFjAcCX2dz6s727UrWP6dqZjbOzJZFMTyRJYbF\n0USW7UTJciZwtJkdDtQijDqLiOSHAnfNz6I68G3CuVujc2u4+3ygN+F3+CkqK6kWHXoh4a7ffDOb\nZman5PDzpABTkiy55VlePwp8AdSLbkvdTCgtyEvLgZrbXkSjrDV2cvzOYlwCHJzNedntWx997t4J\n26plOSbrn9M9hJnjjaMYumeJobaZFcsmjtGEkovzCGUYG7M5TkQk2QriNT/R90DthHP3it5rGYC7\nP+3urYG6QDHgrmj7fHfvClQB7gdeNLPSuf9VJJUpSZZkKwesBtZHtV87q01LlteB5mZ2WlTPew2h\n1mxPYhwP1DKzXmZWysz2NbNttW6PA7eb2cEWNDWzSoTRjh8Ik1iKmVkPEi7CO4lhPbDazA4E+iTs\n+xhYAdxpZnubWRkza52w/ylCbfS5hIRZRCQuBeGan2gc0MnMjo8mGP4TWAtMNbPDzKyNmZUCfose\nWwHM7Dwz2z8aeV5N+LKwNbm/lqQaJcmSbL2BCwgXnUcJEzvylLv/CJwNDCEklwcDMwkjtbsVo7uv\nBk4CzgB+BL7ij/q6wcArwERgDaH2rnR0q+9S4AZCXVw9YFf1agMJE01WExLzFxNiyCTU3B1GGFX+\njpAUb9u/GPgc2OjuH+3ic0RE8lJBuOYnnjuHEO/DQAZhomGnqD65FHAv4Tr+A1ARuDE69RRgXtTV\n4z7gbHfflMRfS1KQhX/fRQqPqEzhe6CLu/8v7njygpmNBha5+y1xxyIiEqeicM2XeGgkWQoFM2tv\nZhWi22T/R5iJPG0XpxVIZnYQ0BkYGXcsIiJxKErXfImPkmQpLI4GFhFun50M/K0wTmgzs7uA2cCd\n7v7dro4XESmkisQ1X+KlcgsRERERkSw0kiwiIiIikkXxuAPIav/99/c6derEHYaIyB6ZMWPGz+6e\n03ZUhYKu2yJSUO3smp1ySXKdOnVIT0+POwwRkT1iZt/u+qjCRddtESmodnbNVrmFiIiIiEgWSpJF\nRIoIM2tgZrMSHmvM7Nosx5iZPWBmC83sMzNrHle8IiJxSrlyCxERyRvuPh9oCr8vwLAMeDnLYR2A\n+tGjJWFlspb5GKaISEpQkiwiUjS1Bb5296z1eJ2B0dFy659ECzYc4O7L8z9EkYJp8+bNLF26lA0b\nNsQdikRKly5NzZo1KVGiRI7PUZIsIlI0dQWe3cH2GsCShNdLo23bJclm1gPoAVCrVq08ClGkYFq6\ndCnlypWjTp06mFnc4RR57s6KFStYunQpdevWzfF5OapJjpZ/nB/VqPXfyXFnmJmbWVrCtgHRefPN\n7OQcRyYiInnCzEoCnYDn9/Q93H2Eu6e5e1rlykWq453ILm3YsIH99ttPCXKKMDP222+/3R7Z3+VI\nclS3Nhw4iTCiMN3Mxrv73CzHlQOuAaYmbGtIGK1oBFQH3jWzQ9x9y25FKSIiydQB+NTdf9zBvmXA\ngQmva0bbRGQ3KEFOLXvy95GTkeQWwEJ3X+Tum4CxhJq1rG4D7gES0/TOwFh33+ju3wALo/cTEUk5\n7vDFF/DQQ/DEE3FHk6fOYcelFgDjgfOjLhdHAauTXY+8eDHcfDMsWpTMdxURSa6cJMnZ1af9LmoR\ndKC7v7G750bn9zCzdDNLz8jIyFHgIiLJ1qMHNG4MPXvCmDFxR5M3zKws4c7gSwnbLjezy6OXE4BF\nhEGNx4Arkx3Djz/CbbfBl18m+51FBGDFihU0bdqUpk2bUq1aNWrUqPH7602bNuXoPS688ELmz5+/\n02OGDx/OM888k4yQOfroo5k1a1ZS3itZcj1xz8z2AoYA3ff0Pdx9BDACIC0tzXMbk4hITmzeDDNm\nQMuW8P778PjjIVHu1w92Y25HgeLu64H9smx7JOG5Az3zMoYKFcLPX37Jy08RKbr222+/3xPOW265\nhX322Yc+ffpsd4y74+7stdeOx0tHjRq1y8/p2TNPLxWxy8lI8q7q08oBhwPvm9li4ChgfDR5T7Vt\nIpISMjNDOcU2W7fC+edDq1Zw6qlh9LhuXRg6FA46CFROmHeUJIvEY+HChTRs2JB//OMfNGrUiOXL\nl9OjRw/S0tJo1KgRgwYN+v3YbSO7mZmZVKhQgf79+9OkSRNatWrFTz/9BMBNN93E0KFDfz++f//+\ntGjRggYNGvDRRx8BsH79es444wwaNmxIly5dSEtLy/GI8W+//cYFF1xA48aNad68OZMnTwbg888/\n5y9/+QtNmzbliCOOYNGiRaxdu5YOHTrQpEkTDj/8cF544YVc/3nlZCR5OlDfzOoSEtyuwLnbdrr7\namD/ba/N7H2gj7unm9lvwBgzG0KYuFcfmJbrqEVEcmj9enjwQbj3XjjiCHjqKahaFQYMgLFj4Ywz\n4I03YMMGeO01KFMm7ogLv/Llw08lyVIUXHstJLuKoGnT8IV+T3z55ZeMHj2atLTQiOzuu++mUqVK\nZGZm0qZNG7p06ULDhg23O2f16tUcd9xx3H333Vx//fWMHDmS/v3/3OzM3Zk2bRrjx49n0KBBvPXW\nWzz44INUq1aNF198kdmzZ9O8ec4X8XzggQcoVaoUn3/+OXPmzOGUU05hwYIFPPTQQ/Tp04ezzz6b\njRs34u68+uqr1KlThzfffPP3mHNrlyPJ7p4J9ALeBuYB49x9jpkNMrNOuzh3DjAOmAu8BfRUZwsR\nyS/ffQdHHhkS4mbNQmlFo0ZQqRIMGQK9esHzz8Onn8Kzz0LHjnFHXDSULh0eSpJF8t/BBx/8e4IM\n8Oyzz9K8eXOaN2/OvHnzmDt37p/OKVOmDB06dADgyCOPZPHixTt877///e9/OmbKlCl07doVgCZN\nmtCoUaMcxzplyhS6desGQKNGjahevToLFy7kr3/9K7fffjv33nsvS5YsoXTp0hxxxBG89dZb9O/f\nnw8//JDy276N50KOapLdfQJhMkfitpuzOfb4LK/vAO7Yw/hERPbI3Llw8smwdi288w6ceCIsXAj/\n93+w337Qrl1Iis3gsMPCQ/JPhQpKkqVo2NMR37xStmzZ358vWLCAYcOGMW3aNCpUqEC3bt122Eu4\nZMmSvz8vVqwYmZmZO3zvUqVK7fKYZDjvvPNo1aoVb7zxBu3bt2fkyJEce+yxpKenM2HCBPr370+H\nDh244YYbcvU5OVpMRESkoHAPLdzS0sLEvA8+CAkyQL16YcT43/+GTp0gm/kqkg8qVlSSLBK3NWvW\nUK5cOfbdd1+WL1/O22+/nfTPaN26NePGjQNCLfGORqqzc8wxx/zePWPevHksX76cevXqsWjRIurV\nq8c111xDx44d+eyzz1i2bBn77LMP5513Hr179+bTTz/NdexallpECo2tW+GSS2DUqDCKPHIkVK8e\nd1SyIxpJFolf8+bNadiwIYceeii1a9emdevWSf+Mq666ivPPP5+GDRv+/siuFOLkk0+mRIkSQEiQ\nR44cyWWXXUbjxo0pUaIEo0ePpmTJkowZM4Znn32WEiVKUL16dW655RY++ugj+vfvz1577UXJkiV5\n5JFHdvgZu8PcU6vjWlpamqenp8cdhogUMFu2wBVXwGOPhZKKW2+Np0OFmc1w97RdH1l47Ml1+5RT\nICMDpk/Po6BEYjRv3jwOUw0XAJmZmWRmZlK6dGkWLFhAu3btWLBgAcWL5/847Y7+XnZ2zdZIsogU\naGvXhs4Vo0bBsmVw443xJciScxUqwIIFcUchInlt3bp1tG3blszMTNydRx99NJYEeU8UjChFRHbg\no4/gvPPgm2+gQ4dQa9y5sxLkgkDlFiJFQ4UKFZgxY0bcYewRJckiUqD89lsoqXjiCZg5E+rUgcmT\n4eij445Mdse2JNldX2qkcHJ3TP9xp4w9KS/W3G4RKRC++goGDw4dKq65BooVC72OZ81SglwQVagQ\nVkH89de4IxFJvtKlS7NixYo9Sswk+dydFStWULp06d06TyPJIpLyrrkGHnggPD/6aHjmGTj++FhD\nklxKXJo6oW2rSKFQs2ZNli5dSkZGRtyhSKR06dLUrFlzt85RkiwiKW3ixJAgX3QR3Hwz1K4dd0SS\nDIlJco0a8cYikmwlSpSgbt26cYchuaQkWURS1vr1cOmlcMghYVJemTJxRyTJUrFi+KnJeyKSqpQk\ni0hK2Lo1TOLaujV0q5g0Ce6/PzyfPFkJcmGzbSR51ap44xARyY4m7olI7KZNCyvjFS8OJUtCgwZw\n+eWw774wfjwcc0zcERYOZlbBzF4wsy/NbJ6Ztcqy/3gzW21ms6LHzXkVS2K5hYhIKtJIsojE6sMP\nQ4/jypXDIiAQ2ro1agTNm6s9WJINA95y9y5mVhLYewfH/M/dO+Z1IEqSRSTVKUkWkdi8/z507Bgm\nbk2cCLs58Vh2g5mVB44FugO4+yZgU1zxlC8ffipJFpFUpXILEck3mzdD//6hjVvPnnDKKaFbxQcf\nKEHOB3WBDGCUmc00s8fNbEfN11qZ2Wwze9PMGmX3ZmbWw8zSzSx9T9pclSwJe++tJFlEUpeSZBHJ\nFytXwsknwz33hK4Vjz8ODRuG0eRq1eKOrkgoDjQHHnb3ZsB6oH+WYz4Fart7E+BB4JXs3szdR7h7\nmrunVa5ceY8C0tLUIpLKlCSLSL648UaYMgWefDIsJ712LUyfHmqRJV8sBZa6+9To9QuEpPl37r7G\n3ddFzycAJcxs/7wKSEmyiKQyJckikud++QVGj4Zu3eD888O2kiU1KS8/ufsPwBIzaxBtagvMTTzG\nzKqZhb8VM2tB+DdiRV7FpCRZRFKZJu6JSJ578kn49Vfo1SvuSIq8q4Bnos4Wi4ALzexyAHd/BOgC\nXGFmmcBvQFd397wKpmJFWL48r95dRCR3lCSLSJ5ZtAjKlYPhw6FVq9DSTeLj7rOAtCybH0nY/2/g\n3/kVT4UKMG9efn2aiMjuyVG5hZm1N7P5ZrbQzLJO9MDMLjezz6Pm81PMrGG0vY6Z/ZbQmP6RP7+7\niBQ2P/4IZ50FBx8MVarAggUaRZY/U7mFiKSyXY4km1kxYDhwEmHix3QzG+/uibVsY6JbdZhZJ2AI\n0D7a97W7N01u2CKSqpYtCyPGv/wCN90ElSqFUoszz4w7Mkk125Jkd9Wni0jqyUm5RQtgobsvAjCz\nsUBnEiZ8uPuahOPLAnlWwyYiqcsdLr00dK6YNg2aNIk7IkllFSrA1q2wbl0oyxERSSU5KbeoASxJ\neL002rYdM+tpZl8D9wJXJ+yqGzWu/8DMjslVtCKSUlatCnXH24waBW++GXohK0GWXalYMfz86ad4\n4xAR2ZGktYBz9+HufjDQD7gp2rwcqBU1rr8eGGNm+2Y9N7crN4lI/lu4MJRVHHYYPPVU6GBx5ZVw\n/PFhNT2RXWnVKvx855144xAR2ZGcJMnLgAMTXteMtmVnLHA6gLtvdPcV0fMZwNfAIVlPSMbKTSKS\nf2bMgGOOCWUVLVqE3sfdu0Pr1vDCC7CXOrBLDhx2GNSvD69ku66fiEh8clKTPB2ob2Z1CclxV+Dc\nxAPMrL67L4hengosiLZXBla6+xYzOwioT+jNKSIp7vvvYcKEUFvcsCF07AibN8OLL8Ktt4alpCdO\nDEnOTTeFxUEGDoTiaiwpOWQGp58OQ4fC6tVQvnzcEYmI/GGX/5y5e6aZ9QLeBooBI919jpkNAtLd\nfTzQy8xOBDYDq4ALotOPBQaZ2WZgK3C5u6/Mi19ERJJn1apQU/zzz7DvvrBmDVx33R/7zz4bHnoo\ndK6AUIMssidOPx0GDw5fyM45J+5oRET+kKMxH3efAEzIsu3mhOfXZHPei8CLuQlQRPLf3XfDihUw\naRIcdxx8/XUYNS5XLowcp6WpZZckR8uWULVqKLlQkiwiqUQ3RkVkO0uWwLBh0K1bmIQHUK9eeIgk\nW7Fi0LkzPP00zJ8PDRrEHZGISKDpNSKynf79Q7/j226LOxIpKm64AcqWhdNOg5UqyBORFKEkWUR+\n98QTMGZMSJRr1447GikqateGl1+Gb78NdzBERFKBkmQRAeDDD0Of4zZt4Oabd328SDK1bg133RUW\no3nvvbijERFRkixS5E2bBs2awdFHhxXQxowJdaIi+e3KK6FmzdBS0D3uaESkqFOSLFKErV4NXbqE\nVm8PPACffRb6H4vEoXTpcBfj449DSzgRkTgpSRYpYtasgfvvDy23rrwyLBrywgtw1VWw335xRyd5\nzcwqmNkLZvalmc0zs1ZZ9puZPWBmC83sMzNrnp/xde8OBx2kiaMiEj+1gBMppLZu/fPy0D//DO3b\nh2Wltxk4MPSqlSJjGPCWu3cxs5LA3ln2dyCsjlofaAk8HP3MFyVKQO/e0LMnfPIJHHVUfn2yiMj2\nNJIsUshs2BBWMUtLg02b/tiekREWBpkzJ3QSmDgRhg+HG2+ML1bJX2ZWnrAS6n8A3H2Tu/+S5bDO\nwGgPPgEqmNkB+Rnn+eeHJaqHDs3PTxUR2Z6SZJFCZONGOOMMePVVmDkzJMEAa9fCKafAokWhe8Dp\np8MJJ4RyixIl4o1Z8lVdIAMYZWYzzexxMyub5ZgawJKE10ujbdsxsx5mlm5m6RkZGUkNcp994NJL\nQxnQkiW7Pl5EJC8oSRYpRK65Jkx4evRROPlkGDQIJk8OJRYzZ8Lzz/+xip4UScWB5sDD7t4MWA/0\n35M3cvcR7p7m7mmVK1dOZowA9OoVOlxoNFlE4qIkWaSQ2JYc9+kDPXrAffeFSXrHHQdz58Izz0DH\njnFHKTFbCix196nR6xcISXOiZcCBCa9rRtvyVe3a8I9/wMMPww8/5Peni4goSRYpFObMgYsvhsaN\n4fbbw7bDD4d//Qv69oWFC+Hss+ONUeLn7j8AS8ysQbSpLTA3y2HjgfOjLhdHAavdfXl+xrnNzTeH\nuvp77onj00WkqFN3C5EC7OefwySnN98MdZxvvQWlSv2x/+qr44tNUtZVwDNRZ4tFwIVmdjmAuz8C\nTABOARYCvwIXxhVovXpwwQVhNLlPH6jxp8poEZG8o5FkkQJiy5Zw2/n77yEzM3Sx6NwZJk0Ko8ff\nfANNmsQdpaQ6d58V1RIf4e6nu/sqd38kSpCJulr0dPeD3b2xu6fHGe9NN4X/9u+6K84oRKQoUpIs\nUgAsWRIS4AMOCKNpBxwArVvDRx/BU0+FNm777x93lCLJV7cuXHQRPPYYfPdd3NGISFGiJFkkxc2e\nHRLiJUvCZLzhw+Gkk2DxYhg8OCwrLVKYbevlfccd8cYhIkWLapJFUtT330P//vD001ClCrz/PjRr\nFvZdeWWsoYnkq1q1Qt/kRx+Ffv3CstUiInlNI8kiKWj69LBi3vPPhwlLc+b8kSCLFEU33ADFiv3R\nvUVEJK8pSRZJMZ98AsceG7pUTJsG994L++0Xd1Qi8apeHa64AkaPhgUL4o5GRIoCJckiKWTLlpAI\nVK4MU6eGvsciEvTrByVLhpUkRUTyWo6SZDNrb2bzzWyhmf1pCVMzu9zMPjezWWY2xcwaJuwbEJ03\n38xOTmbwIoXNf/4Ds2aFCXlVqsQdjUhqqVYtLFf9zDMwf37c0YhIYbfLJNnMigHDgQ5AQ+CcxCQ4\nMibqp9kUuBcYEp3bEOgKNALaAw9F7ycikdWr4aWXQj/YAQNCqcVZZ8UdlUhq6tMnlCJpFT4RyWs5\n6W7RAljo7osAzGws0JmEpUzdfU3C8WUBj553Bsa6+0bgGzNbGL3fx0mIXaRAyMyE4gn/p335ZVgu\n+vPPw4Ign38ejilWLCwl/dBDYBZfvCKprEqV0Oni4YfhlltC5wsRkbyQk3KLGsCShNdLo23bMbOe\nZvY1YST56t08t4eZpZtZekZGRk5jF0l5L7wQaigrVYIGDaB2bWjYMEw+KlMmLApy/fXwv//BunWh\n1KJRo7ijFkltffqEn/fdF28cIlK4Ja1PsrsPB4ab2bnATcAFu3HuCGAEQFpamu/icJECYdWqUD/Z\nsCEcdxysWAGlS0O9enDZZWFynojsvlq14Lzzwip8N92k+n0RyRs5SZKXAQcmvK4ZbcvOWODhPTxX\npNAYMAAyMuDNN9XjWCTZ+vWDJ56AoUPhzjvjjkZECqOclFtMB+qbWV0zK0mYiDc+8QAzq5/w8lRg\nWxfL8UBXMytlZnWB+sC03IctkrrWrIFrrw2rg117rRJkkbzQoAGceWZYpv2XX+KORkQKo10mye6e\nCfQC3gbmAePcfY6ZDTKzTtFhvcxsjpnNAq4nKrVw9znAOMIkv7eAnu6+JQ9+D5GU8M03YfLdAw+E\nfsdaHUwk7wwYEL6UDh8edyQiUhiZe2qVAKelpXl6enrcYYjstowMaN0afv4Z3ngDWrWKOyKJg5nN\ncPe0uOPIT3Fet089NaxSuWgRlC8fSwgiUoDt7JqtFfdEkuCrr+Ckk2DJEnjtNSXIkprMbHHCwk9/\nymrN7HgzWx3tn2VmN8cR5+4YNAhWroT77487EhEpbJLW3UKkqFm1Ct57D6ZPD+UVpUvDyy+H0WSR\nFNbG3X/eyf7/uXvHfIsml448Miy+M2QI9OwJVavGHZGIFBYaSRbZDYsWwZQpMHBg6HncpUtYQrpt\nW/jiC2jfPu4IRYqe224LC/PccUfckYhIYaIkWSQH3MMCBgcfDMccE27xtmsXEuZ160KJRfXqcUcp\nsksO/NfMZphZj2yOaWVms83sTTPLdmmbVFoE6pBD4OKL4ZFHwhdZEZFkUJIssgtbt8LVV4eax0sv\nhbffhoULw2p6rVuHlfNECoij3b050AHoaWbHZtn/KVDb3ZsADwKvZPdG7j7C3dPcPa1yCqyMc/PN\nYWn3gQPjjkRECgslySI74B4eGzfCP/4B//439O4deh+3axdGlEUKGndfFv38CXgZaJFl/xp3Xxc9\nnwCUMLP98z3QPVCjRvgy+8wz8NlncUcjIoWBkmSRBBs3hkl41apBpUpw6KEwdizcfXeoPTaLO0KR\nPWNmZc2s3LbnQDvgiyzHVDML/5WbWQvCvxEr8jvWPdWvX2gD16dP+JIrIpIb6m4hEtm0CU44AT76\nCNq0CSt6LVgAd90FXbvGHZ1IrlUFXo5y4OLAGHd/y8wuB3D3R4AuwBVmlgn8BnT1VGumvxOVKsEt\nt4SVLsePh86d445IRAoyLSYiRZo7rF0L++4byimGDIEnn4TzztOosewZLSYSr82bw1Lwv/4Kc+eG\n1owiItnRYiIi2RgwINyebd78jz6r55+vBFmkoCpRIpRMffNNKJMSEdlTSpKlyPrwQ7j33lBaUaJE\nKLW47764oxKR3DrhBDj3XLjzTpgzJ+5oRKSgUk2yFEnr10P37mFBkFdfhXLl4o5IRJJp6NDQrvHi\ni8MX4mLF4o5IRAoajSRLkfDLL/DcczB7Nvz0U1gh7+uvYdQoJcgihVHlyjBsGEydGlo4iojsLo0k\nS6G2eXPonTpqVGjvBmHxD/ewGMjxx8canojkoXPPDX2Tb7ghdLqoUyfuiESkINFIshRamZnQrVtY\nqvb882HyZHjoIfjb3+D99+Hvf487QhHJS2bh/38zuOwy9U4Wkd2jJFkKJXe4/HIYNy4sAjJiBBxz\nDFxxRRhZatky7ghFJD/UqhW6XPz3v/Dww3FHIyIFiZJkKZQeegj+8x+48caw+paIFF1XXgnt28P1\n12vJahHJOdUkS6GxahVMmhQm5N1wA3TsCIMGxR2ViMRtr73CIkFNmoTVM6dPh7Jl445KRFKdRpKl\nwPvxR+jfP7RzO+MM6NsXDjuIVvkAACAASURBVDsMnnoq/OMoIlKlCjz9NHz5ZVi2WkRkV5RCSIE1\nezZcdVWYsX7vvdChA0yZAj/8ALNmQYUKcUcoIqmkbdvwhfrxx0NLSBGRnclRkmxm7c1svpktNLP+\nO9h/vZnNNbPPzGyimdVO2LfFzGZFj/HJDF6KpiVLoEULaNo0zFzv2hXmzQv/6LVuDVWragRZRHbs\n1luhVSu45BLVJ4vIzu0ylTCzYsBwoAPQEDjHzBpmOWwmkObuRwAvAPcm7PvN3ZtGj05JiluKqEWL\n4NhjYf78sEDA8uWhB3KDBnFHJiIFQYkS8PzzsO++cNppoVxLRGRHcjLe1gJY6O6L3H0TMBbonHiA\nu09y91+jl58ANZMbpghkZECbNrBmDbz3HvTsCfvvH3dUIlLQ1KgB48eHa8rf/gYbNsQdkYikopwk\nyTWAJQmvl0bbsnMx8GbC69Jmlm5mn5jZ6Ts6wcx6RMekZ2Rk5CAkKWoyM+Gss8KS0m+/DUceGXdE\nIlKQHXlkmMj38cdw8cVaaERE/iyplZtm1g1IAwYnbK7t7mnAucBQMzs463nuPsLd09w9rXLlyskM\nSQqJfv3CKnmPPAJpaXFHIyKFwd//DnfcAWPGqF2kiPxZTvokLwMOTHhdM9q2HTM7EbgROM7dN27b\n7u7Lop+LzOx9oBnwdS5iliJm7FgYMiSUV1xwQdzRiBRsZrYYWAtsATKjQYzE/QYMA04BfgW6u/un\n+R1nfhkwIMxxuOWW0ClH1xgR2SYnI8nTgfpmVtfMSgJdge26VJhZM+BRoJO7/5SwvaKZlYqe7w+0\nBuYmK3gpPNzh009DvXGi2bPDrdDWrUOiLCJJ0SaaTL2j+zIdgPrRowdQqBdzNoPHHoMTTggdL958\nc9fniEjRsMsk2d0zgV7A28A8YJy7zzGzQWa2rVvFYGAf4Pksrd4OA9LNbDYwCbjb3ZUky3Y2boTz\nzw81glWrwjnnhH+onn8ejjkGypcPz0uWjDtSkSKhMzDag0+ACmZ2QNxB5aWSJeGll6BxYzj9dHj1\n1bgjEpFUkKNlqd19AjAhy7abE56fmM15HwGNcxOgFG5Ll8K558L//hfqjteuDeUVY8eG/S1awLhx\ncECh/idaJF858F8zc+BRdx+RZX92k7WXJx5kZj0II83UqlUr76LNJ+XLw8SJ0L49dOkS6pTPPDPu\nqEQkTjlKkkWSbc2asPhH376weTM8+2xYFATgX/+CCRNCD+SLL9YIskiSHe3uy8ysCvCOmX3p7pN3\n902i5HoEQFpaWqHoDVGxIrzzDpx6argebdwI3brFHZWIxEVJsuSrn3+G3r3DSPGmTWHlq9GjoV69\nP44pWTLc8hSR5EuYTP2Tmb1M6IWfmCTnaLJ2YbXvvvDWW9CpUygD27Ah1CqLSNGjxXsl30ycCA0b\nhlHjyy6DDz+EKVO2T5BFJO+YWVkzK7ftOdAO+CLLYeOB8y04Cljt7sspQsqWhddfh5NPhksvheHD\n445IROKgkWTJF99/HxYDqVo1JMuNVakuEoeqwMuhyxvFgTHu/paZXQ7g7o8Q5p+cAiwktIC7MKZY\nY1WmDLzyCpx9NvTqFUaUe/eOOyoRyU9KkiXPucNFF8Fvv8HLL0ODBnFHJFI0ufsioMkOtj+S8NyB\nnvkZV6oqVSp01vnHP6BPnzCxeODA0DZORAo/JcmSZ+bMgbvuglmzwvPhw5Ugi0jBUqJE6HSx995w\n663wxRcwahSUKxd3ZCKS11STLEm3ZQuMHAl/+UvoUlG7Ntx7L1xxRdyRiYjsvuLFQ2J8333hblha\nGsyYEXdUIpLXlCRL0mRmhl7HNWqE1m0tW8LcufDGG/DPf+oWpYgUXGahJnniRFi/Ho46ShP6RAo7\nJcmSNP36hRHjVq3CAiDvvgvVqsUdlYhI8hx/PHz2GXToECb09ekDW7fGHZWI5AUlyZIUo0fDkCFw\n1VXhduSZZ0KxYnFHJSKSfJUqhetcr15w//2hp/KqVXFHJSLJpiRZcm3OnND3uE2b8A+GiEhhV6wY\nPPAA/Pvf8N//hjrl2bPjjkpEkklJsuTKhg1wzjlhlapnnw0zwUVEigIz6NkTPvggXAuPOircVROR\nwkFJsuyRb76BYcPglFPg88/DzO+qVeOOSkQk/7VqBZ9+GpLkCy6AK6+EjRvjjkpEckt9kiVH3EOn\nii++gPHjYezYMFmlVi0YPDgkyyIiRVXVqvDOO3DjjWEC8/TpYfDg8MPjjkxE9pRGkmWXli6F004L\nF/uuXeHVV+G662DxYvj22zC7W0SkqCteHO65B156Kdxta94c/u//QimGiBQ8SpJlp156CRo1gkmT\nwsV/1iz4+efQVL927bijExFJPX/7G3z5ZRhUuP12aNoUJk+OOyoR2V1KkmWHtm6FG26AM86AQw8N\ndcd9+0KTJlC6dNzRiYiktv33D5P43n471Ccfd1zoArR6ddyRiUhOKUmWP9myBS69FO66C3r0CCMg\nBx0Ud1QiIgVPu3ZhLkfv3vD449CsGaSnxx2ViOSEkmTZzpYtYXb2yJEwcCA88giUKhV3VCIiBVfZ\nsqFEbcoUyMyEv/41JM3ffx93ZCKyM0qS5XfucMUV8MwzcOedcMstoQ+oiIjkXqtWMHNm6C0/bBjU\nrQt33BESZxFJPTlKks2svZnNN7OFZtZ/B/uvN7O5ZvaZmU00s9oJ+y4wswXR44JkBi/JkZkZVozq\n2hUeeyy0MBowIO6oRCQvmFkxM5tpZq/vYF93M8sws1nR45I4YizM9tsPnnwSFiyA00+Hm26C1q1D\npyARSS27TJLNrBgwHOgANATOMbOGWQ6bCaS5+xHAC8C90bmVgIFAS6AFMNDMKiYvfMmttWuhbVs4\n+WSYMCEkyLfdFndUIpKHrgHm7WT/c+7eNHo8nl9BFTV168Jzz8G4cTB/fljW+r334o5KRBLlZCS5\nBbDQ3Re5+yZgLNA58QB3n+Tuv0YvPwFqRs9PBt5x95Xuvgp4B2ifnNAlt1avhg4d4MMP4dFHISMj\ntCtSiYVI4WRmNYFTASW/KeLMM8PCI5UrhwGLCy+E5cvjjkpEIGdJcg1gScLrpdG27FwMvLk755pZ\nDzNLN7P0jIyMHIQkufXKK2FxkKlTw+p5PXqotZtIETAU6Ats3ckxZ0Slcy+Y2YHZHaTrdvLUrw/T\npkG/fjBmTOhN/9prcUclIkmduGdm3YA0YPDunOfuI9w9zd3TKleunMyQZAduvTU0u69UKcy27tIl\n7ohEJK+ZWUfgJ3efsZPDXgPqRKVz7wBPZnegrtvJtc8+cPfdoSd9nTrQqRNcfTWsXx93ZCJFV06S\n5GVA4mhCzWjbdszsROBGoJO7b9ydcyX/DBkSulZ07x56dbZsGXdEIpJPWgOdzGwxoWzuBDN7OvEA\nd1+RcP1+HDgyf0OUQw6Bjz8OCfKDD4Y7flqtTyQeOUmSpwP1zayumZUEugLjEw8ws2bAo4QE+aeE\nXW8D7cysYjRhr120TfJZZmZYMa9371AD9/jjUKJE3FGJSH5x9wHuXtPd6xCu4++5e7fEY8zsgISX\nndj5BD/JI6VKhRZxkydD8eLQpk0YZd66syIZEUm6XSbJ7p4J9CIkt/OAce4+x8wGmVmn6LDBwD7A\n81HboPHRuSuB2wiJ9nRgULRN8tHs2XDiiTB4cOiD/PTTUKxY3FGJSCrIci2/2szmmNls4Gqge3yR\nyTHHwIwZoSRuwIAwsW/RorijEik6zN3jjmE7aWlpnq41O5Niw4aQFD/xBJQvD0OHhjILEck7ZjbD\n3dPijiM/6bqdt9zhP/8JdwIzM8NiT1ddBXtpOTCRXNvZNVv/ixVSK1dCu3ahaX3fvvDNN0qQRUQK\nIjO45BKYMweOPx6uvRaOPTb0VxaRvKMkuRCaMycsf7qtvds990BFLeEiIlKg1awJr78Oo0fD3LnQ\ntCncd59qlUXyipLkQmbsWGjRIiwU8s47cNZZcUckIiLJYgbnnReS5Pbt4Z//hFNOCYtBiUhyKUku\nJDZvDrfgzjkHmjWDTz8Nt+NERKTwqVYNXnoJHnkE3n8fGjeG558P9csikhxKkguB5ctDi6Bhw+Ca\na2DSJKhePe6oREQkL5nBZZeF1fpq1Ah3Dtu0gZdfhi1b4o5OpOBTklzATZ0KzZvDzJlhOdOhQ9X/\nWESkKDniiPBvwdChoUXc3/8eJm6vXh13ZCIFm5LkAuy118Kowd57h5GEc86JOyIREYlD8eLhTuKi\nRfDoo2EhkqOPhilTVIIhsqeUJBdQjz4Kp58eliz9+GNo1CjuiEREJG7Fi0OPHvDWW7B0aViQpF49\n1SuL7AklyQXMqlWh7/Hll4eZzZMmQZUqcUclIiKppG1bWLIEnnoqLCZ11lnQsSPMmhV3ZCIFh5Lk\nAiIzE66+OkzIGzwYLr0UXn0VypaNOzIREUlF++wD3bqFcrz77w+lF82awZlnql5ZJCeUJBcAW7fC\nxRfDgw+GuuMZM2DEiHBbTUREZGeKF4frr4fFi2HgQHjllVCv/N13cUcmktqUJKe4H36Ac88NKywN\nGgQjR4ZuFiIiIrujYkW45ZZQr/zdd9CkCTz8sNrFiWRHSXIKe+YZqF8/NIy/4w646aa4IxIRkYKu\nbdtQgtGsGVx5ZVilderUuKMSST1KklPU5MnQvXsYNZ47F264ITSOFxERya0GDWDiRHj22XDH8qij\noHNneP11jSyLbKMkOQXNmwddusDBB8P48aF9j4iISDKZQdeu8OWXcOON8MkncNpp8Je/wP/+F3d0\nIvFTkpxC1q2DXr3C6kmZmaF7RfnycUclIoWJmRUzs5lm9voO9pUys+fMbKGZTTWzOvkfoeS3cuXg\n9ttDX+XRoyEjA449Fs4+G779Nu7oROKjJDlFbN0aJug9/HBo7zZvXrgdJiKSZNcA87LZdzGwyt3r\nAf8C7sm3qCR2JUrAeefB/Plhgt9rr8Ghh4ZR5rVr445OJP8pSY7Z//4XSip69w4XpGHD4KGHoGrV\nuCMTkcLGzGoCpwKPZ3NIZ+DJ6PkLQFszzYYoavbeO7SKmz8fzjgD7rwzlP0NGQK//hp3dCL5R0ly\njMaPD7e0OneGoUPDUqI9e8YdlYgUYkOBvsDWbPbXAJYAuHsmsBrYb0cHmlkPM0s3s/SMjIy8iFVi\nduCB8PTToVa5ceMwmHPIIeHfLpGiQElyTH78ES65JPSp/OQTeO89GD5cHSxEJG+YWUfgJ3efkYz3\nc/cR7p7m7mmVK1dOxltKimrZEt59Fz74ACpVCgM7J54Izz0X5tKIFFY5SpLNrL2ZzY8mc/Tfwf5j\nzexTM8s0sy5Z9m0xs1nRQ98/gQ0b4IILYM2a0Au5ZUto00Yr6IlInmoNdDKzxcBY4AQzezrLMcuA\nAwHMrDhQHliRn0FK6jr22LDi6+DBsHBh6IxRoUJoVZqWBk2bwhtvxB2lSPLsMkk2s2LAcKAD0BA4\nx8waZjnsO6A7MGYHb/GbuzeNHp1yGW+Bt2JF+Ab+9tthmelGjeKOSESKAncf4O413b0O0BV4z927\nZTlsPHBB9LxLdIznY5iS4kqUgD59YNGicAe0f3/Yf/8wj2bTptBC7p57QP/VSGGQk7HLFsBCd18E\nYGZjCZM75m47wN0XR/uyq3MTwghyu3YwZ064TXXWWXFHJCJFnZkNAtLdfTzwH+ApM1sIrCQk0yJ/\nstde4Q5omzZ/bPv1V7joopA4L1oUSgh1h1QKspz85/v7RI7IUqDlbnxGaTNLBzKBu939lawHmFkP\noAdArVq1duOtC5Y+feDTT0P/405FfkxdROLi7u8D70fPb07YvgE4M56opKDbe++wgt9BB8Fdd8Gy\nZTByJFSpEndkInsmP77j1Xb3ZWZ2EPCemX3u7l8nHuDuI4ARAGlpaYXuJs3ixfDkk+Fb9fXXK0EW\nEZHCySy0jKtZE667Dg47DK66KpRkHH88HH543BGK5FxOJu79PpEjUjPaliPuviz6uYgwctFsN+Ir\n8AYNgrp1Q2P2Dh3Ct2sREZHC7MorYeZMaNgQbr01JMpNm8LNN4fSQ5GCICdJ8nSgvpnVNbOShBq1\nHHWpMLOKZlYqer4/YXb13J2fVXiMHBkasp9zTpgJPGEClCwZd1QiIiJ5r2HDsGDWr7/Cd9+FVWVv\nuw0qVw5LXk+eHHeEIju3yyQ5aijfC3ibsJTpOHefY2aDzKwTgJn9xcyWEmrZHjWzOdHphwHpZjYb\nmESoSS4SSfIHH4TFQU46KZRaHHxw3BGJiIjkvzJlwsIko0fDpEkhWX7vPTjuuDDx7/33445QZMcs\n1br7pKWleXp6etxh5EpGRlgkpFw5mD4d9t037ohEJL+Y2Qx3T4s7jvxUGK7bkr9++w1GjAjt4pYv\nDz2YBw4MSbMW1ZL8tLNrtlbcS7KtW8NCIStXhjZvSpBFRES2V6YMXHMNfP01PPBAKEls2zYky+++\nqz7LkhqUJCfR1q1wxRXw5ptw//1hkoKIiIjsWJkyYVLf11/Dv/8N33wTyhSbN4c77gjdoUTioiQ5\nSdyhV69w+2jAgDCzV0RERHatdGno2TMkyw89BKVKwU03Qb16cOGFsGBB3BFKUaQkOQnc4eqr4eGH\noW/f8O1XNVUiIiK7p1SpcEf2k0/g22/DKPPYsXDoofCPf4SOGFu2xB2lFBVKkpOgX79wm+j66+Hu\nu5Ugi4iI5FatWvCvf4WSi969w2q1xx0XFirp2TN0kVLtsuQlJcm5NHMmDB4c2r3dd58SZBERkWSq\nWhXuvTd0wRg7Fo4+GkaNCiv4HXooDBkSJsuLJJuS5Fy68UaoWDG0sVGCLCIikjfKlQuLkDz/fGi1\n+tRTYbnr3r2hRg3o3h2mTtXosiSPkuRc+OCD0MliwACoUCHuaERERIqGsmWhWzf48EOYPTskyC++\nCEcdBUceCY89BuvXxx2lFHRKkvfQxo1w3XVQvXroaiEiIiL574gjwsT5778PP7dsCSWQ2/59njNn\n1+8hsiNKkvdQv36hHnn48NDnUUREROJTrhxcfjnMmhVGmDt1CiPKhx8e6phvvBFeeQU2bYo7Uiko\nlCTvgVdegWHDQmua00+POxoRkZwxs9JmNs3MZpvZHDO7dQfHdDezDDObFT0uiSNWkT1lBn/9a6hZ\nXrYsTPpbty78/NvfQteMfv3gv/9VSYbsnJLk3fTRR3DuuaHmafDguKMREdktG4ET3L0J0BRob2ZH\n7eC459y9afR4PH9DFEme/feHf/4zjC6vWxfmEaWlhVVxTz4ZatcOJRqZmXFHKqlISfJumDMHTj01\nzKJ9443Q9FxEpKDwYF30skT0UC8AKRJKlYL27eH112HVqpAwH354WCG3USN44gmVYsj2lCTnUEYG\ndOwYls78739D30YRkYLGzIqZ2SzgJ+Add5+6g8POMLPPzOwFMzswm/fpYWbpZpaekZGRpzGLJFu5\nciFhnjQpdMUoUyYsf33ggWHkecYMtZITJck5smkTdOkSGpm/+irUrRt3RCIie8bdt7h7U6Am0MLM\nDs9yyGtAHXc/AngHeDKb9xnh7mnunla5cuW8DVokj5jB3/8eJuJPmACtW8PQoaEko3ZtuPrqMDC2\nZAls3Rp3tJLflCTvwq+/QufOYb34kSOhRYu4IxIRyT13/wWYBLTPsn2Fu2+MXj4OHJnfsYnkNzPo\n0AFeeikMiI0aBc2ahe4YJ58cJvvVqBG2b9gAc+eGSYFSuClJ3on166Fdu/At8rHHwoQ9EZGCyswq\nm1mF6HkZ4CTgyyzHHJDwshMwL/8iFInf/vuHxUlefRV+/hnefTdM7qtbFy66CPbeO9Qw16wZappH\njVJpRmFVPO4AUlnfvqGbxXPPwZlnxh2NiEiuHQA8aWbFCIMk49z9dTMbBKS7+3jgajPrBGQCK4Hu\nsUUrErOyZaFt2/Do0SPkA3PmwGGHhRHnceNC4vzGG6E1bI0acUcsyWSeYl9/0tLSPD09Pe4wePvt\nUNR//fWhVYyISE6Y2Qx3T4s7jvyUKtdtkfy2dWvIEW68MYwmn3MOXHZZ6NNsFnd0khM7u2ar3GIH\nfv01fDNs1AjuuCPuaERERCQV7bVX6IYxf35oJffSS2F1v4MOCneghw2D336LO0rZUzlKks2svZnN\nN7OFZtZ/B/uPNbNPzSzTzLpk2XeBmS2IHhckK/C89NRTYQ344cNDyzcRERGR7NStGxLixEl/M2fC\ntdeG0owHHgh3qH/+Oe5IZXfsMkmOateGAx2AhsA5ZtYwy2HfEerWxmQ5txIwEGgJtAAGmlnF3Ied\nd7ZuDe1fjjwSjj027mhERESkoChXLkz6e+klWLgQ3nsPypeHa64JJZzVqoWGAI89poS5IMjJSHIL\nYKG7L3L3TcBYoHPiAe6+2N0/A7J2ETyZ0Kx+pbuvIvTcbE8Ke+st+PJLuO461ROJiIjInmvTJiyJ\nvWRJWLikb1/45pswCTBrwuwOU6eGxU1UopEacpIk1wCWJLxeGm3LidycG4shQ6B6dXWzEBERkdwz\nC+3ijj8e7rwTvvoqlGJkTZjr1IGjjgqLlx14INxyi5LluKXExL1UWd70449h4sRwW6RkydjCEBER\nkULKDJo2/XPCfMQRMGJEqF0+5hi49VZo3DiMLGdmxh110ZSTPsnLgAMTXteMtuXEMuD4LOe+n/Ug\ndx8BjIDQSiiH7510t94amohfeWVcEYiIiEhRsS1hbtp0++3t2oVBuyuuCCPL1atDkyahb/MFF8Cp\np6okND/kZCR5OlDfzOqaWUmgKzA+h+//NtDOzCpGE/baRdtSzscfh29vffvCPvvEHY2IiIgUZW3b\nhuWvX30VWrYMdcsffwynnRYmAb77bmg2IHlnl0myu2cCvQjJ7TzCCk1zzGxQtCoTZvYXM1sKnAk8\namZzonNXArcREu3pwKBoW8q5/XaoXFmjyCIiIpIaiheHTp1Ct4xp00IN89ChMGMGnHQS1K8Pd90F\nP/wQd6SFU45qkt19grsf4u4Hu/sd0baboyVMcffp7l7T3cu6+37u3ijh3JHuXi96jMqbXyN3vvsO\n3nwTLr883MoQERERSTUlSoR5U0uXwjPPQK1acMMNYdJfv36walXcERYuOalJLvRGRan7RRfFG4eI\niIjIrpQuDeeeGx5ffRUmAQ4eHBY06dABDjgAvv4aqlaFFi3CaHStWn+cv3YtLFsGhx4a3+9QEKRE\nd4s4bdkCI0fCiSeGb2IiIiIiBcUhh8ATT4R+zJddFsoynn0WVqyAd96Bq64K+c2JJ8KHH4aezS1b\nwuGHh+Mke0V+JHnixFBuce+9cUciIiIismeOOCKMJA8b9sc29zCiPGYMPPooHH007Ltv2HfkkdCt\nG6xZE3o1q1vGnxX5keSHH4ZKleD00+OORERERCR5zKBePbj55lCW8X//F0aeJ08OKwC2bRvmYx1/\nPLzxhiYAZlWkk+SvvgqtVa68EkqVijsaERERkbxRtiwMGgTTp4eey3vvHZoWjBgBc+ZAx46hlrlR\no5BUL14cd8TxK9JJ8v33h5X1evWKOxIRERGR/FWsGFx6KXz7Lbz/Ptx3H1SpAnfcAQcfDGedFUaY\nN22KO9J4FNkk+ccf4cknoXv3MPtTRKSwM7PSZjbNzGab2Rwzu3UHx5Qys+fMbKGZTTWzOvkfqYjk\np7Jl4bjjoHfvUIbx7bfQp09YsKRjx1DHXKVKWBnwttvCnfiioEgmye7wz3+Gb0a9e8cdjYhIvtkI\nnODuTYCmQHszOyrLMRcDq9y9HvAv4J58jlFEYlazJtxzT6hRfv310CGjS5eQLA8cCA0ahIl/gweH\nhLqwKpLdLR5+GJ56KvxF168fdzQiIvnD3R1YF70sET08y2GdgVui5y8A/zYzi84VkSKkZEk49dTw\n2GbpUnj+eRg7Fvr2DY/DD4djj/3jccAB8cWcTEVuJDk9Ha69Fk45JRSmi4gUJWZWzMxmAT8B77j7\n1CyH1ACWALh7JrAa2G8H79PDzNLNLD0jIyOvwxaRFFGzJlx3HUydGtrL3X031KgBo0dD165QvTp0\n7gwffACZmXFHmztFKknetAkuvBAqVw4jyXsVqd9eRATcfYu7NwVqAi3M7PA9fJ8R7p7m7mmVK1dO\nbpAiUiAcdFBYDvutt8KS2NOnhzZzU6aEtnKVKoVByXvuCetSfPklbN4cd9Q5V6TKLe6+G774AsaP\nD39xIiJFlbv/YmaTgPbAFwm7lgEHAkvNrDhQHlgRQ4giUoAULw5paeHRr1+oZf7gg9A14803/zju\nwAPhhhugXDn4/HM4+2xo1iy2sHeqyCTJEybA7bfDOefAaafFHY2ISP4zs8rA5ihBLgOcxJ8n5o0H\nLgA+BroA76keWUR2R9myIfk9++zw+qefYO7cMMnvkUfgiiv+OHbIkNAxo0cPqFgxnnizUySS5Mcf\nDyvKNGkCDz4YdzQiIrE5AHjSzIoRyu3GufvrZjYISHf38cB/gKfMbCGwEugaX7giUhhUqRIeAOef\nDx9/DGXKhFrmyy+H/v1hwIDQYq5NG2jePIxMly8fSjrq1oUSJfI/7kKfJD/9dGiU3b59mI25zz5x\nRyQiEg93/wz4041Nd7854fkG4Mz8jEtEig4z+Otf/3j94ovw0UehZnnSJBg+HDZu3P6cEiWgYUM4\n4ojQSWPLlvDo0eOP5DtPYk21u2hpaWmenp6+R+euWwfLl4fZlJs3hwLxbt2gdWt4++3QykREJC+Z\n2Qx3T4s7jvyUm+u2iEii334LS2K7w8qVsGhRKNX47DOYPRu+//6PY6tUCeUbp5wCpUrt2eft7Jpd\nKEaSH/v/9u42RqqzDOP4/wrYta2Rl4KIsLq0Re2KWAgxEIEYUQtNA5GqoZJYI0nTpMaqTQxI0sR+\nMxq1JthabdU02DZSVEJam4qN8RNv2lJeunaxCLuhspaKia+gtx+ehzCdzu6cXXbOmV2uX3Kyc14m\nc+09M/c8u+ecOd9PrXvdawAAB3dJREFUxxsfP/76dd3dsH27B8hmZmZm7e7yy+G66y7ML1362vVn\nzqQx3dGjsH49rF2b5ufPT9+qMdLBciPjYpA8YwYsW5YGxJ2dqVgTJ6Z/zy9fDpMnV53QzMzMzC7W\npEnp57x5sGdP+haNPXugv390B8gwTgbJq1enyczMzMwuDR0dcPPNaWoFX07DzMzMzKyOB8lmZmZm\nZnUKDZIlrZTUI6lX0sYG6zskPZbX75bUlZd3SfqnpGfzdP/oxjczMzMzG31Nj0nOXzq/hXRlpj5g\nr6QdEXG4ZrMNwKsRca2kdaQrOOXrrHA0Iq4f5dxmZmZmZi1T5D/J7wd6I+KPEfEf4FFgTd02a4Af\n59vbgBWSNHoxzczMzMzKU2SQPAs4UTPfl5c13CYizgFngKvyujmSfi/pN5KWNXoASbdJ2idp38DA\nwLB+ATMzMzOz0dbqE/dOAm+PiAXAl4CfSHpz/UYR8UBELIqIRdOnT29xJDMzMzOzoRUZJPcDnTXz\ns/OyhttImghMAl6JiH9HxCsAEbEfOAq882JDm5mZmZm1kiJi6A3SoPcPwArSYHgv8KmIOFSzzR3A\neyPi9nzi3tqI+KSk6cDpiPivpKuB3+btTg/xeAPAn0bwu0wD/jKC+7VSO2aC9szlTMU4UzFVZnpH\nRFxSu8Tct1vOmYpxpmLaMRNUl2vQnt302y0i4pykzwFPAROAhyLikKR7gH0RsQN4EHhYUi9wGliX\n774cuEfSWeB/wO1DDZDz443ow0XSvohYNJL7tko7ZoL2zOVMxThTMe2YaTxz324tZyrGmYppx0zQ\nnrkKXZY6Ip4AnqhbdnfN7X8Bn2hwv8eBxy8yo5mZmZlZqXzFPTMzMzOzOuNpkPxA1QEaaMdM0J65\nnKkYZyqmHTPZ67Xj8+RMxThTMc5UXNvlanrinpmZmZnZpWY8/SfZzMzMzGxUeJBsZmZmZlZnXAyS\nJa2U1COpV9LGijJ0SnpG0mFJhyTdmZdPlfS0pBfzzykVZJuQLw2+M8/PkbQ71+sxSZeVnGeypG2S\nXpB0RNKSqusk6Yv5eTso6RFJb6yiTpIeknRK0sGaZQ1ro+Q7Od8BSQtLzPT1/PwdkPQzSZNr1m3K\nmXok3VBWppp1d0kKSdPyfCl1suLcs5tmc89unsk9e3iZ3LNHYMwPkiVNALYAq4Bu4BZJ3RVEOQfc\nFRHdwGLgjpxjI7ArIuYCu/J82e4EjtTMfw34VkRcC7wKbCg5z73ALyPi3cD7crbK6iRpFvB5YFFE\nzCN9H/g6qqnTj4CVdcsGq80qYG6ebgPuKzHT08C8iJhPutjQJoD8ml8HvCff57v5PVpGJiR1Ah8F\njtcsLqtOVoB7diHu2UNwzx5RJvfskYiIMT0BS4CnauY3AZvaINcvgI8APcDMvGwm0FNyjtmkN+mH\ngJ2ASFe0mdiofiXkmQS8RD5ptGZ5ZXUCZgEngKmk7w7fCdxQVZ2ALuBgs9oA3wNuabRdqzPVrfsY\nsDXffs37j3QRoiVlZQK2kT7EjwHTyq6Tp0LPm3v20Dncs5tncs8eZqa6de7ZBacx/59kLrxZzuvL\nyyojqQtYAOwGZkTEybzqZWBGyXG+DXyZdMVDgKuAv0bEuTxfdr3mAAPAD/PuxB9IupIK6xQR/cA3\nSH/JngTOAPuptk61BqtNu7z2Pws8mW9XlknSGqA/Ip6rW9UudbKk7Z4P9+whuWcPn3t2AWOhZ4+H\nQXJbkfQm0lUGvxARf6tdF+lPotK+c0/STcCpiNhf1mMWMBFYCNwXEQuAv1O3m66COk0B1pA+DN4G\nXEmD3ULtoOzaNCNpM2m39daKc1wBfAW4u9m2ZrXcs5tyz74I7tmD5hgTPXs8DJL7gc6a+dl5Wekk\nvYHUbLdGxPa8+M+SZub1M4FTJUb6ALBa0jHgUdLuu3uByZLOX5K87Hr1AX0RsTvPbyM14Crr9GHg\npYgYiIizwHZS7aqsU63BalPpa1/SZ4CbgPX5g6DKTNeQPjCfy6/32cDvJL21wkzWWNs8H+7Zhbhn\nD597dnNjomePh0HyXmBuPqv1MtIB6DvKDiFJwIPAkYj4Zs2qHcCt+fatpOPeShERmyJidkR0kery\n64hYDzwDfLyiTC8DJyS9Ky9aARymwjqRdtktlnRFfh7PZ6qsTnUGq80O4NP5TODFwJmaXXwtJWkl\naZfw6oj4R13WdZI6JM0hnXixp9V5IuL5iHhLRHTl13sfsDC/3iqrkzXknj0I9+zC3LOHyT175EHH\n/ATcSDpb8yiwuaIMS0m7VA4Az+bpRtLxZLuAF4FfAVMryvdBYGe+fTXpTdAL/BToKDnL9cC+XKuf\nA1OqrhPwVeAF4CDwMNBRRZ2AR0jH2J0lNY0Ng9WGdELPlvy6f550pndZmXpJx4ydf63fX7P95pyp\nB1hVVqa69ce4cBJIKXXyNKznzz27eT737KEzuWcPL5N79ggmX5bazMzMzKzOeDjcwszMzMxsVHmQ\nbGZmZmZWx4NkMzMzM7M6HiSbmZmZmdXxINnMzMzMrI4HyWZmZmZmdTxINjMzMzOr83+Ld9Hz3fZ7\nfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MPTokoLYxCvI",
    "outputId": "10b5dea3-b316-49fb-ab6a-b9995506fe0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope the united states and you are not not gone ' said the king 'and to find her eyes nor try the little head again to save her head from the little tea about on it ' and the white rabbit said ' said the king in a officers of the court that as your sea was going into a sun and a user who notifies you to ask all it as your history of the terms of the united states on the top of the house ' and she said to herself to herself in her eyes by the jury\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = tokenizer.index_word[predicted[0]]\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJzIYX4Fw574"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "190_Generating_LSTM_Sentences_AliceWonderland_next_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
