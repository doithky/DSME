{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 080. seq2seq language translation\n",
    "\n",
    "### Encoder-Decoder model\n",
    "\n",
    "\n",
    "- Seq2seq language translation 의 decoder 부분은 Language Model 의 text poetry generation 과 동일함  \n",
    "\n",
    "\n",
    "- 영어-한국어 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 256                # encoding space 의 latent dimensionality\n",
    "NUM_SAMPLES = 10000         # number of samples to train on\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력 data list 작성  \n",
    "\n",
    "### 1. input_texts     : original language 의 input text  \n",
    "\n",
    "\n",
    "### 2. Teacher Forcing 용 input / target data 생성\n",
    "\n",
    "- target_texts_inputs  : 1 만큼 offset 된 target language sentence $\\rightarrow$ `<sos>....`  \n",
    "- target_texts  : target language sentence  $\\rightarrow$ `.....<eos>`\n",
    "\n",
    "\n",
    "\n",
    "- data 는 http://www.manythings.org/anki/  (Tab-delimited Bilingual Sentence Pairs) 에서 download  \n",
    "\n",
    "\n",
    "    - English(input) + `\\t` + The Other Language(target) + `\\t` + Attribution(기여자) 형식으로 구성 \n",
    "        ex)\n",
    "        - Hi.\t안녕.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #8355888 (Eunhee)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = tf.keras.utils.get_file(\"kor.txt\",\n",
    "                 \"https://github.com/ironmanciti/NLP_lecture/raw/master/data/kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples : 3318\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "original_texts = []\n",
    "translation_inputs = []\n",
    "translation_targets = []\n",
    "\n",
    "# load data\n",
    "for line in open(file_path, 'r', encoding='utf-8'):\n",
    "   \n",
    "    if '\\t' not in line:     # next line 이동\n",
    "        continue\n",
    "        \n",
    "    # input 과 target translation 구분\n",
    "    input_text, translation, attribution = line.split('\\t')\n",
    "        \n",
    "    # target input 과 output 을 teacher forcing 입력 구성\n",
    "    translation_input = '<sos> ' + translation\n",
    "    translaton_target = translation + ' <eos>'\n",
    "\n",
    "    original_texts.append(input_text)     # original text\n",
    "    \n",
    "    translation_inputs.append(translation_input)   \n",
    "    translation_targets.append(translaton_target)\n",
    "\n",
    "print(\"num_samples :\", len(original_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input :\n",
      "[\"Don't lie anymore, OK?\", \"Don't you laugh at me.\", 'French is fascinating.', 'French is interesting.', 'French is very useful.', 'He looked quite tired.', 'He was about to speak.', 'He was born in Africa.', 'I called Tom for help.', \"I didn't come by taxi.\"]\n",
      "\n",
      "Teacher Forcing Input :\n",
      "['<sos> 거짓말 하지 마세요, 알았죠?', '<sos> 날 비웃지마.', '<sos> 프랑스어는 매력적이야.', '<sos> 프랑스어는 흥미로워.', '<sos> 프랑스어는 아주 유용해.', '<sos> 그사람은 좀 지쳐보였어.', '<sos> 그사람이 말하려고 했어.', '<sos> 그는 아프리카에서 태어났다.', '<sos> 나는 톰에게 도움을 요청했다.', '<sos> 택시로 안 왔어.']\n",
      "\n",
      "Teacher Forcing Target\n",
      "['거짓말 하지 마세요, 알았죠? <eos>', '날 비웃지마. <eos>', '프랑스어는 매력적이야. <eos>', '프랑스어는 흥미로워. <eos>', '프랑스어는 아주 유용해. <eos>', '그사람은 좀 지쳐보였어. <eos>', '그사람이 말하려고 했어. <eos>', '그는 아프리카에서 태어났다. <eos>', '나는 톰에게 도움을 요청했다. <eos>', '택시로 안 왔어. <eos>']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Input :\")\n",
    "print(original_texts[1100:1110])\n",
    "print(\"\\nTeacher Forcing Input :\")\n",
    "print(translation_inputs[1100:1110])\n",
    "print(\"\\nTeacher Forcing Target\")\n",
    "print(translation_targets[1100:1110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "- language 가 2 개 이므로 언어별로 서로 다른 tokenizer 생성. 따라서, 2 개의 word_index 구성\n",
    "\n",
    "### Input Text 의 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yesterday was a good day.',\n",
       " \"You can't erase the past.\",\n",
       " 'You have to study French.',\n",
       " 'You need to study French.',\n",
       " 'You should exercise more.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_texts[1500:1505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[126, 12, 6, 94, 153],\n",
       " [4, 68, 1547, 7, 449],\n",
       " [4, 17, 3, 142, 29],\n",
       " [4, 116, 3, 142, 29],\n",
       " [4, 119, 961, 89]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_original = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer_original.fit_on_texts(original_texts)\n",
    "\n",
    "original_sequences = tokenizer_original.texts_to_sequences(original_texts)\n",
    "original_sequences[1500:1505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique input token 수 : 2395\n",
      "Input Text 의 단어 수 : 2396\n",
      "Input Text 의 최대 길이 : 101\n"
     ]
    }
   ],
   "source": [
    "word2idx_original = tokenizer_original.word_index\n",
    "print(f'unique input token 수 : {len(word2idx_original)}')\n",
    "\n",
    "num_words_original = min(MAX_VOCAB_SIZE, len(word2idx_original) + 1)\n",
    "print(\"Input Text 의 단어 수 :\", num_words_original)\n",
    "\n",
    "max_len_original = max(len(s) for s in original_sequences)\n",
    "print(\"Input Text 의 최대 길이 :\", max_len_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Text 의 tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos> 어제는 좋은 날이었다.', '<sos> 과거를 지울 순 없어.', '<sos> 넌 프랑스어를 공부해야 돼.', '<sos> 넌 프랑스어를 공부할 필요가 있어.']\n",
      "['어제는 좋은 날이었다. <eos>', '과거를 지울 순 없어. <eos>', '넌 프랑스어를 공부해야 돼. <eos>', '넌 프랑스어를 공부할 필요가 있어. <eos>']\n"
     ]
    }
   ],
   "source": [
    "print(translation_inputs[1500:1504])\n",
    "print(translation_targets[1500:1504])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input language 의 tokenize\n",
    "- 주의 사항 : $<sos>, <eos>$때문에 special character 를 filtering 하면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1164, 87, 2706], [1, 696, 2707, 2708, 21], [1, 52, 37, 548, 124], [1, 52, 37, 2709, 247, 6]]\n",
      "[[1164, 87, 2706, 2], [696, 2707, 2708, 21, 2], [52, 37, 548, 124, 2], [52, 37, 2709, 247, 6, 2]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_translation = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=\"\")\n",
    "tokenizer_translation.fit_on_texts(translation_inputs + translation_targets) \n",
    "\n",
    "translation_input_sequences  = tokenizer_translation.texts_to_sequences(translation_inputs)\n",
    "translation_target_sequences = tokenizer_translation.texts_to_sequences(translation_targets)\n",
    "\n",
    "print(translation_input_sequences[1500:1504])\n",
    "print(translation_target_sequences [1500:1504])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output language 의 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique output tokens : 5324\n",
      "Target 언어의 단어 수 : 5325\n",
      "Target 언어의 최대 길이 : 90\n"
     ]
    }
   ],
   "source": [
    "word2idx_translation = tokenizer_translation.word_index\n",
    "print(f'unique output tokens : {len(word2idx_translation)}')\n",
    "\n",
    "num_words_translation = len(word2idx_translation) +1\n",
    "print(\"Target 언어의 단어 수 :\", num_words_translation)\n",
    "\n",
    "max_len_translation = max(len(s) for s in translation_target_sequences)\n",
    "print(\"Target 언어의 최대 길이 :\", max_len_translation )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequence padding\n",
    "\n",
    "\n",
    "#### 주의 사항\n",
    "- encoder 는 thought vector 생성 목적이므로 default (pre) 로 padding\n",
    "\n",
    "- decoder 는 teacher forcing 을 해야하므로 post 로 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape : (3318, 101)\n",
      "encoder_inputs[0] :  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 126  12   6  94 153]\n",
      "\n",
      "decoder input shape : (3318, 90)\n",
      "decoder_inputs[0] :  [   1 1164   87 2706    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "\n",
      "encoder target shape : (3318, 90)\n",
      "encoder_targets[0] :  [1164   87 2706    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = pad_sequences(original_sequences, maxlen=max_len_original)\n",
    "print(\"encoder input shape :\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0] : \", encoder_inputs[1500])\n",
    "\n",
    "decoder_inputs = pad_sequences(translation_input_sequences, maxlen=max_len_translation, padding=\"post\")\n",
    "print(\"\\ndecoder input shape :\", decoder_inputs.shape)\n",
    "print(\"decoder_inputs[0] : \", decoder_inputs[1500])\n",
    "\n",
    "decoder_targets = pad_sequences(translation_target_sequences, maxlen=max_len_translation, padding=\"post\")\n",
    "print(\"\\nencoder target shape :\", decoder_targets.shape)\n",
    "print(\"encoder_targets[0] : \", decoder_targets[1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained word embedding 값을 transfer learning\n",
    "\n",
    "- Embedding layer 의 weight 를 pre-trained model 로 초기화  \n",
    "\n",
    "\n",
    "- glove.6B 의 EMBEDDING_DIM version 사용  \n",
    "    - space 로 구분된 text file \n",
    "    - 첫번째는 word 이고 두번째 이후는 weight vector 값이다\n",
    "\n",
    "\n",
    "- word index 가 1 부터 시작하므로 0 padding 감안하여 num_words 는 len(word2idx)+1, 혹은 MAX_VOCAB_SIZE 중 작은 것 선택  \n",
    "\n",
    "\n",
    "- embedding_dict dictionary : key - word, value - embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = tf.keras.utils.get_file(\"glove.6B.100d.txt\", \n",
    "             \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(transfer_learning=True):\n",
    "\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    with open(glove_path, encoding=\"utf8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            values = line.split()                                           # 각 줄을 읽어와서 word_vector에 저장\n",
    "            word = values[0]                                              # 첫번째 값은 word\n",
    "            coefs = np.asarray(values[1:], dtype='float32')  # 두번째 element 부터 마지막까지 100 개는 해당 단어의 임베딩 벡터의  값\n",
    "            embeddings_dict[word] = coefs\n",
    "                \n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))    # zero 로 초기화   \n",
    "    \n",
    "    if transfer_learning:    \n",
    "        print(\"word 갯수 =\", num_words)\n",
    "        print(embedding_matrix.shape)\n",
    "\n",
    "        for word, i in word2idx_original.items():\n",
    "            if i < MAX_VOCAB_SIZE:\n",
    "                embedding_vector = embeddings_dict.get(word)\n",
    "                if embedding_vector is not None:       # 해당 word 가 없으면 all zero 로 남겨둠\n",
    "                    embedding_matrix[i] = embedding_vector\n",
    "                    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx_original) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding layer 작성\n",
    "\n",
    "- encoder 와 decoder 의 Embedding layer 에 pre-trained embedding weight 를 초기값으로 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 갯수 = 2396\n",
      "(2396, 100)\n"
     ]
    }
   ],
   "source": [
    "# create embedding layer\n",
    "embedding_matrix = make_embedding(transfer_learning=True)\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "- encoder 와 decoder 의 embedding, lstm 및 dense layer 를 training 할 목적의 model 작성  \n",
    "\n",
    "- encoder 는 decoder 에 states [h, c] 만 전달\n",
    "\n",
    "- prediction 을 위한 model 은 training model 에서 만들어진 layer 들의 weight 를 이용하여 별도 작성  \n",
    "\n",
    "### Training : Encoder + Teacher Forcing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Input (InputLayer)      [(None, 101)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Input (InputLayer)      [(None, 90)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 101, 100)     239600      Encoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 90, 256)      1363200     Decoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 365568      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 90, 256), (N 525312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Output (Dense)          (None, 90, 5325)     1368525     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,862,205\n",
      "Trainable params: 3,862,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs_ = Input(shape=(max_len_original), name='Encoder_Input')\n",
    "\n",
    "# pre-trained embedding layer 사용\n",
    "x = embedding_layer(encoder_inputs_)\n",
    "\n",
    "encoder_outputs, h, c = LSTM(LATENT_DIM, return_state=True)(x)\n",
    "\n",
    "# encoder 는 hidden state and cell state 만 decoder 로 전달 --> thought vector\n",
    "encoder_states = [h, c]\n",
    "\n",
    "# Decoder\n",
    "# decoder 는 [h, c] 를 initial state 로 사용\n",
    "decoder_inputs_ = Input(shape=(max_len_translation,), name=\"Decoder_Input\")\n",
    "\n",
    "# decode word embedding 은 pre-trained vector 를 사용 않음\n",
    "decoder_embedding = Embedding(num_words_translation, LATENT_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_)\n",
    "\n",
    "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# final layer\n",
    "decoder_dense = Dense(num_words_translation, activation='softmax', name='Decoder_Output')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Create the model object\n",
    "model_teacher_forcing = Model([encoder_inputs_, decoder_inputs_], decoder_outputs)\n",
    "\n",
    "#Compile the model and train it\n",
    "model_teacher_forcing.compile(loss='sparse_categorical_crossentropy', \n",
    "                              optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model_teacher_forcing.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model_teacher_forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_teacher_forcing.fit([encoder_inputs, decoder_inputs], decoder_targets, \n",
    "                         batch_size=BATCH_SIZE, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(history.history['loss'], label='loss')\n",
    "ax1.plot(history.history['val_loss'], label='val_loss')\n",
    "ax1.legend()\n",
    "\n",
    "# accuracies\n",
    "ax2.plot(history.history['accuracy'], label='acc')\n",
    "ax2.plot(history.history['val_accuracy'], label='val_acc')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_teacher_forcing.save('seq2seq_translation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions - Inference phase\n",
    "\n",
    "- prediction 을 위한 별도의 encoder model \n",
    "- encoder 의 states 를 initial state 로 받는 decoder model 작성  \n",
    "\n",
    "- encoder 는 training 단계와 동일하게 input_text 를 입력으로 받고 encoder_states 를 출력으로 하므로 이전에 define 한 encoder_input_ 과 encoder_states 변수 재사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_model = Model(encoder_inputs_, encoder_states)\n",
    "\n",
    "# Decoder\n",
    "decoder_state_input_h = Input(shape=(LATENT_DIM,), name='Decoder_hidden_h')\n",
    "decoder_state_input_c = Input(shape=(LATENT_DIM,), name='Decoder_hidden_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,), name='Decoder_input')\n",
    "x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# output, hidden states 를 저장\n",
    "decoder_outputs, h, c = decoder_lstm(x, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [h, c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)  \n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,    #decoder_model.predict([target_seq] + states_value)\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "encoder_model.summary()\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse word2idx dictionary to get back words during prediction\n",
    "idx2word_original = dict((i, w) for w, i in word2idx_original.items())\n",
    "\n",
    "idx2word_translation = dict((i, w) for w, i in word2idx_translation.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "   # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "   # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "   # target sequence 의 첫번째 character 를 start character (<sos>) 로 설정 \n",
    "   # [[2.]]\n",
    "    target_seq[0, 0] = word2idx_translation['<sos>']\n",
    "\n",
    "   # <eos> 가 decode 에서 생성되면 break\n",
    "    eos = word2idx_translation['<eos>']\n",
    "\n",
    "   # Create the translation\n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_translation):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "       # argmax 로 가장 확률 높은 단어 선택 --> greedy selection\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        if eos == idx:  # End sentence of EOS\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx > 0:      # idx 0 은 zero padding 된 sequence 이므로 skip\n",
    "            word = idx2word_translation[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # 생성된 word 를 decoder 의 다음 input 으로 사용\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "       # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(output_sentence)\n",
    "\n",
    "for _ in range(5):\n",
    "    i = np.random.choice(len(original_texts))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    \n",
    "    translation = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input:', original_texts[i])\n",
    "    print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt = \"Your lips are red.\"\n",
    "input_sequence = tokenizer_original.texts_to_sequences([txt])\n",
    "encoder_input = pad_sequences(input_sequence, maxlen=max_len_original)\n",
    "\n",
    "translation = decode_sequence(encoder_input)\n",
    "print('-')\n",
    "print('Input:', txt)\n",
    "print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
