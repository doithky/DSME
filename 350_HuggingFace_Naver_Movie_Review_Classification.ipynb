{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "350_HuggingFace_Naver_Movie_Review_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "izA3-6kffbdT"
      },
      "source": [
        "# BERT Fine Tuning Naver 영화감상평 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oC3MFzEHiY0I",
        "outputId": "5c1a3800-85ad-455b-9838-c4dff5d18bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU 사용 :\", torch.cuda.get_device_name())\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU available, CPU 사용\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 사용 : Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "To9ENLU90WGl",
        "outputId": "edb395f9-8edb-4501-ef5d-2ad8dacb3bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VySQT1PbX4zI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zQ-42fh0hjsF"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cyoj29J24hPX",
        "colab": {}
      },
      "source": [
        "DATA_TRAIN_PATH = tf.keras.utils.get_file(\"ratings_train.txt\", \n",
        "                                \"https://github.com/ironmanciti/NLP_lecture/raw/master/data/naver_movie/ratings_train.txt\")\n",
        "DATA_TEST_PATH = tf.keras.utils.get_file(\"ratings_test.txt\", \n",
        "                                \"https://github.com/ironmanciti/NLP_lecture/raw/master/data/naver_movie/ratings_test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aj322-y3iznR",
        "outputId": "890bd091-d7cb-413a-ef6a-aeeed9dd8a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "train_data = pd.read_csv(DATA_TRAIN_PATH, delimiter='\\t')\n",
        "print(train_data.shape)\n",
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LXEN60Y8ykM0",
        "outputId": "8cf0aead-9b42-46b5-e9b4-759c148bc79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "train_data.dropna(inplace=True)\n",
        "train_data.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 149995 entries, 0 to 149999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        149995 non-null  int64 \n",
            " 1   document  149995 non-null  object\n",
            " 2   label     149995 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 4.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywyQV5GGjBzZ",
        "outputId": "7d4ec9f3-2aa9-47e6-9952-496487407810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "test_data = pd.read_csv(DATA_TEST_PATH, delimiter='\\t')\n",
        "print(test_data.shape)\n",
        "test_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                           document  label\n",
              "0  6270596                                                굳 ㅋ      1\n",
              "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
              "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zHwOiRLiyxth",
        "outputId": "7b9008ce-23a0-4875-e2fb-4ceac512d495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "test_data.dropna(inplace=True)\n",
        "test_data.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 49997 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        49997 non-null  int64 \n",
            " 1   document  49997 non-null  object\n",
            " 2   label     49997 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PRc2L89hh1Tf"
      },
      "source": [
        "몇개의 sentence 가 \"positive\" (value 1) 이고 몇개가  \"negative\" (having the value 0) 인지 count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TixERP1giznY",
        "outputId": "eb969e7e-f1c8-42c4-db73-2734e29d0e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "df_train = train_data.sample(n=50000, random_state=1)\n",
        "df_test = test_data.sample(n=5000, random_state=1)\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 3)\n",
            "(5000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jGvcfcCP5xpZ",
        "outputId": "a8509513-138a-4feb-9632-f9c2a4eb6599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df_train['label'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    25069\n",
              "1    24931\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7_MO08_KiAOb"
      },
      "source": [
        "## Loading the Pre-trained BERT model\n",
        "\n",
        "### BertModel\n",
        "- Bert 모델 변환기는 top layer 가 제거된 raw hidden state 를 출력\n",
        "- 반환값:\n",
        "    - last_hidden_state (torch.FloatTensor of shape (batch_size, sequence_length, hidden_size)): Sequence of hidden-states at the output of the last layer of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uLuTdzsOZEsG",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZDBMn3wiSX6"
      },
      "source": [
        "## Model #1: Preparing the Dataset\n",
        "문장을 BERT에 전달하려면 먼저 필요한 형식으로 문장을 처리하기 위해 최소한의 처리가 필요합니다.\n",
        "\n",
        "### Tokenization\n",
        "첫 번째 단계는 문장을 토큰화하는 것입니다. BERT가 원하는 형식으로 word 와 subword 로 나눕니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dg82ndBA5xlN",
        "outputId": "1816656b-8dde-4312-cf07-7847bb0c7608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "tokenized_train = df_train['document'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized_test = df_test['document'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.2 s, sys: 84.4 ms, total: 10.3 s\n",
            "Wall time: 10.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mHwjUwYgi-uL"
      },
      "source": [
        "### Padding\n",
        "\n",
        "토큰 화 후, 각 문장은 토큰 list 로 표시됩니다. BERT 가 example 을 one batch 로 한 번에 처리하도록 하기 위해 padding 에 의해 같은 길이의 list 로 만들어야 하고 이것을 2-d array 로 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jnO_olqbbrlT",
        "outputId": "91be9d5c-88bf-4f7e-8539-5a78da544401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "tokenized_train.values"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([101, 113, 9926, 34907, 20626, 58931, 24974, 122, 114, 9532, 25503, 12030, 28911, 9367, 19855, 47869, 9682, 9634, 21386, 136, 8924, 11261, 119351, 12605, 20308, 12453, 117, 9792, 73352, 21876, 20173, 9294, 36553, 11287, 52560, 9391, 11664, 9640, 18784, 12030, 12508, 9304, 12508, 19709, 9684, 52560, 10892, 8932, 118651, 14523, 48549, 119, 8905, 119377, 11102, 117, 9604, 78123, 11102, 117, 9684, 89523, 42769, 15387, 9792, 73352, 21876, 20173, 47058, 8982, 28188, 11664, 9294, 36553, 11287, 52560, 9597, 10530, 19709, 9792, 73352, 21876, 100698, 11018, 9670, 14871, 15387, 9637, 12945, 22333, 43022, 113, 9069, 18227, 114, 63783, 9641, 42337, 14801, 119, 119, 102]),\n",
              "       list([101, 68409, 108578, 25258, 9569, 25486, 10739, 9246, 32158, 10530, 9117, 119138, 119081, 48345, 102]),\n",
              "       list([101, 9294, 12508, 118907, 12508, 17594, 9706, 35866, 48533, 119, 84703, 20173, 9519, 118671, 119169, 119, 8996, 24974, 12092, 9531, 118809, 119136, 11664, 9353, 11261, 71568, 82823, 8996, 24974, 12092, 9555, 11664, 9065, 118775, 48533, 119, 110148, 11513, 9682, 54141, 9471, 14153, 9356, 29935, 16323, 23990, 12508, 119, 119, 119, 119, 9638, 12092, 9663, 12092, 9519, 25503, 11664, 8996, 11287, 9460, 68055, 55635, 37909, 12424, 8982, 32537, 11287, 37909, 41605, 27654, 9041, 118713, 119, 119, 119, 9065, 118775, 32679, 119, 119, 102]),\n",
              "       ...,\n",
              "       list([101, 8933, 13890, 105197, 9848, 16323, 37341, 9091, 16985, 11903, 25503, 11018, 9657, 14867, 13890, 14867, 9519, 33077, 12092, 9420, 66540, 33305, 11903, 102]),\n",
              "       list([101, 9379, 66016, 24974, 42428, 28578, 9359, 19105, 35506, 18623, 9523, 11903, 102]),\n",
              "       list([101, 9659, 118959, 32158, 119, 119, 119, 102])], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__4a1oW1iY0v",
        "outputId": "83f77150-ee27-478f-e3da-f983d06833bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(tokenizer.decode(tokenized_train.values[0]))\n",
        "print(tokenizer.decode(tokenized_test.values[-1]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] ( 평점조절용 1 ) 애니인데 분위기가 좀 음산? 그로테스크하고, 캐릭터들이 무민가족 빼고 인간인지 뭔지 다른 종족은 기괴해요. 괴팍한, 우울한, 종말론적인 캐릭터들이 많이 나오고 무민가족 외에 다른 캐릭터간에는 정상적인 의사소통 ( 대화 ) 아닌 일방적.. [SEP]\n",
            "[CLS] 성조기를 들고 날으는 슈퍼맨... 영화는 좋았지만 어쩔수 없다 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wtHEe8GRb9jM",
        "outputId": "4f872f1d-1dd7-4f21-f8a4-6c7a35127781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_len = max([len(i) for i in tokenized_train.values] + [len(i) for i in tokenized_test.values])\n",
        "max_len"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cwd6NzeQ6lyP",
        "outputId": "c9cb105c-9e4d-4ede-b5d2-4a736ad715b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist([len(i) for i in tokenized_train.values] + [len(i) for i in tokenized_test.values], bins=50)\n",
        "None"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ffBfz17dcP64",
        "outputId": "77f0f8f8-c998-48f7-acf0-8accdba48750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "max_len = 40\n",
        "\n",
        "padded_train = pad_sequences(tokenized_train.values, maxlen=max_len, padding='post', truncating='post')\n",
        "padded_test = pad_sequences(tokenized_test.values, maxlen=max_len, padding='post', truncating='post')\n",
        "print(padded_train)\n",
        "print('-------------------------------------------------------------')\n",
        "print(padded_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   101    113   9926 ...   9640  18784  12030]\n",
            " [   101  68409 108578 ...      0      0      0]\n",
            " [   101   9294  12508 ...  11513   9682  54141]\n",
            " ...\n",
            " [   101   8933  13890 ...      0      0      0]\n",
            " [   101   9379  66016 ...      0      0      0]\n",
            " [   101   9659 118959 ...      0      0      0]]\n",
            "-------------------------------------------------------------\n",
            "[[  101  9405 62200 ...     0     0     0]\n",
            " [  101  9328 40032 ...     0     0     0]\n",
            " [  101 10709 86181 ...     0     0     0]\n",
            " ...\n",
            " [  101 62849 17655 ...     0     0     0]\n",
            " [  101  9706 16439 ... 13764 61250 10739]\n",
            " [  101  9434 20626 ...     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZKC0wbCCdDR2",
        "outputId": "84cef52f-aa14-4a42-dde1-892f642260ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(padded_train.shape)\n",
        "print(padded_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 40)\n",
            "(5000, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sDZBsYSDjzDV"
      },
      "source": [
        "### Masking\n",
        "입력을 처리 할 때 추가 한 패딩을 무시(마스크)하도록 다른 변수를 만들어야 하는데, 이 것을 attention_mask 라 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12fHKXErdhui",
        "outputId": "b277fad5-d430-41d9-8840-671c8470de1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "attention_mask_train = np.where(padded_train !=0, 1, 0 )\n",
        "attention_mask_test = np.where(padded_test !=0, 1, 0 )\n",
        "print(attention_mask_train.shape)\n",
        "print(attention_mask_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 40)\n",
            "(5000, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jK-CQB9-kN99"
      },
      "source": [
        "## Model #1: Fine Tuning 시작\n",
        "\n",
        "`model ()`함수는 BERT를 통해 문장을 실행. 처리 결과는`last_hidden_states`로 반환."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "39UVjAV56PJz",
        "colab": {}
      },
      "source": [
        "model.to(device)\n",
        "\n",
        "input_ids_train = torch.tensor(padded_train).to(torch.int64)\n",
        "attention_mask_train = torch.tensor(attention_mask_train)\n",
        "\n",
        "input_ids_test = torch.tensor(padded_test).to(torch.int64)\n",
        "attention_mask_test = torch.tensor(attention_mask_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hP-OYF2KiY1D",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_mask_train)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_mask_test)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bIpEmYLbiY1H",
        "outputId": "3455c0f7-3151-4176-e15d-e97361bca77d",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import time\n",
        "s = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states_train = []\n",
        "    for batch in dataloader_train:\n",
        "\n",
        "        hidden = model(batch[0].to(device), batch[1].to(device))\n",
        "\n",
        "        if len(last_hidden_states_train) == 0:\n",
        "            last_hidden_states_train = hidden[0].to(\"cpu\")\n",
        "        else:\n",
        "            last_hidden_states_train = torch.cat((last_hidden_states_train, hidden[0].to(\"cpu\")), dim=0)\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    last_hidden_states_test = []\n",
        "    for batch in dataloader_test:\n",
        "\n",
        "        hidden = model(batch[0].to(device), batch[1].to(device))\n",
        "\n",
        "        if len(last_hidden_states_test) == 0:\n",
        "            last_hidden_states_test = hidden[0].to(\"cpu\")\n",
        "        else:\n",
        "            last_hidden_states_test = torch.cat((last_hidden_states_test, hidden[0].to(\"cpu\")), dim=0)\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"elapse time: {time.time() - s}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elapse time: 473.8182876110077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GSzxCntXiY1J",
        "outputId": "52ad7bd4-1d20-49a0-bcdb-0fd019af83df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(last_hidden_states_train.shape)\n",
        "print(last_hidden_states_test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 40, 768])\n",
            "torch.Size([5000, 40, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FoCep_WVuB3v"
      },
      "source": [
        "- 필요한 출력 부분 만 슬라이스. 그것은 각 문장의 첫 번째 토큰에 해당하는 출력. \n",
        "- BERT가 문장 분류를하는 방식은 모든 문장의 시작 부분에`[CLS]`(분류 용)라는 토큰을 추가하는 것임. 해당 토큰에 해당하는 출력은 전체 문장에 대한 임베딩으로 간주 될 수 있음.\n",
        "\n",
        "- 로지스틱 회귀 모델의 feature 로 사용되므로`features` 변수에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C9t60At16PVs",
        "outputId": "f06627dc-91bc-4bc5-cb3b-bd10a8cd752e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "features_train = last_hidden_states_train[:,0,:]\n",
        "features_test = last_hidden_states_test[:,0,:]\n",
        "print(features_train.shape)\n",
        "print(features_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 768])\n",
            "torch.Size([5000, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_VZVU66Gurr-"
      },
      "source": [
        "어떤 문장이 긍정인지 부정인지를 나타내는 레이블을 `labels` 변수에 할당."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JD3fX2yh6PTx",
        "outputId": "012fd981-e2f3-4595-fe13-c7fa18aa294e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "labels_train = torch.tensor(df_train['label'].values.astype(\"float32\"))\n",
        "labels_test = torch.tensor(df_test['label'].values.astype(\"float32\"))\n",
        "\n",
        "print(labels_train.shape)\n",
        "print(labels_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000])\n",
            "torch.Size([5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KCT9u8vAwnID"
      },
      "source": [
        "## LogisticRegression model 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ho4LVY5lOMos",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, n_inputs):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(n_inputs, 128)\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        self.linear3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(torch.relu(x))\n",
        "        yhat = torch.sigmoid(self.linear3(torch.relu(x)))\n",
        "        return yhat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lKnJHqhwOuz1",
        "outputId": "d86ed6aa-81b4-4426-a35a-8fa491972de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "classifier = LogisticRegression(features_train.shape[1])\n",
        "classifier.to(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(\n",
              "  (linear1): Linear(in_features=768, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t3xGoHIKPAcv",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tswsyIlAP59I",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset_train = TensorDataset(features_train, labels_train)\n",
        "loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "dataset_test = TensorDataset(features_test, labels_test)\n",
        "loader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4Huhe_1PAND",
        "outputId": "226e65d7-44e5-4e7b-8634-9b7dd0a4354a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "LOSS = []\n",
        "\n",
        "for epoch in range(100):\n",
        "    for i, (x, y) in enumerate(loader_train):\n",
        "        yhat = classifier(x.to(device))\n",
        "        loss = criterion(yhat.to(\"cpu\"), y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        LOSS.append(loss)\n",
        "    if epoch % 20 == 0:\n",
        "        print(\"epoch---\", epoch)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch--- 0\n",
            "epoch--- 20\n",
            "epoch--- 40\n",
            "epoch--- 60\n",
            "epoch--- 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hXysuUq-WE8e",
        "colab": {}
      },
      "source": [
        "accuracy = []\n",
        "for x, y in loader_test:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    z = classifier(x)\n",
        "    accuracy.append((sum(z > 0.5).item() / sum(y)).item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9YtSfGNUWEr9",
        "outputId": "4a3c1db5-6c14-4421-85b3-1a1f012c2a11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(accuracy)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9149061856390555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4oXT-ss3rScY",
        "colab": {}
      },
      "source": [
        "x = '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나'\n",
        "tokenized = tokenizer.encode(x, add_special_tokens=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cNtHrX7miY1l",
        "outputId": "0299e105-e893-481a-99c9-1b379b827ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "tokenized"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 100,\n",
              " 119,\n",
              " 119,\n",
              " 119,\n",
              " 9928,\n",
              " 58823,\n",
              " 30005,\n",
              " 11664,\n",
              " 9757,\n",
              " 118823,\n",
              " 30858,\n",
              " 18227,\n",
              " 119219,\n",
              " 119,\n",
              " 119,\n",
              " 119,\n",
              " 119,\n",
              " 9580,\n",
              " 41605,\n",
              " 25486,\n",
              " 12310,\n",
              " 20626,\n",
              " 23466,\n",
              " 8843,\n",
              " 118986,\n",
              " 12508,\n",
              " 9523,\n",
              " 17196,\n",
              " 16439,\n",
              " 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJK0VlG5rkaR",
        "outputId": "5e2bc1da-1cb1-48ac-b911-974257e37b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer.decode(tokenized)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] [UNK]... 포스터보고 초딩영화줄.... 오버연기조차 가볍지 않구나 [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u5BVsetyrscM",
        "outputId": "713d2506-c2a8-4417-98ac-a8ea9562531f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "padded = pad_sequences([tokenized], maxlen=max_len, padding='post')\n",
        "padded"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   101,    100,    119,    119,    119,   9928,  58823,  30005,\n",
              "         11664,   9757, 118823,  30858,  18227, 119219,    119,    119,\n",
              "           119,    119,   9580,  41605,  25486,  12310,  20626,  23466,\n",
              "          8843, 118986,  12508,   9523,  17196,  16439,    102,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vfmU6Nwyr5bc",
        "outputId": "b724f12e-f22a-45a9-ecf3-13e52d137d7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "attention_mask = np.where(padded !=0, 1, 0 )\n",
        "attention_mask"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66U_cswttLlr",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded).to(torch.int64).to(device)\n",
        "attention_mask = torch.tensor(attention_mask).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3lPYzBZLtjWM",
        "outputId": "a9cec2b9-4e1b-45d2-8741-e2df4e987469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "hidden = model(input_ids, attention_mask)\n",
        "hidden[0].shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 40, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Q5Qfcotv8t8",
        "colab": {}
      },
      "source": [
        "features = hidden[0][0 ,0, :].to(\"cpu\").detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tuAsBcQvuCyc",
        "outputId": "4ce6c9dc-eaa5-4ff5-83df-55304b45d6b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier(features.to(device)).item()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03743727132678032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zckHMYyWu8rq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}