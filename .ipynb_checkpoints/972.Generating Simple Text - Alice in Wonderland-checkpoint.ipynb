{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Simple Text - Alice in Wonderland\n",
    "\n",
    "- 161793 글자로 이루어진 text 를 10 글자 단위로 잘라 input data 를 만들고 뒤 따라오는 글자를 label data 로 만들어 supervised learning  \n",
    "\n",
    "      ex) “alice lear”  - “n” \n",
    "           “lice learn”  - “e”\n",
    "           “ice learne” – “d”  \n",
    "       \n",
    "- Validation 은 seed 가 되는 10 글자 data 를 주고 이어서 만드는 100 글자 문장이 의미 있는지 여부 육안으로 검토\n",
    "\n",
    "      ex) seed : “alice look”  \n",
    "          output : “alice looked at the mouse was a trite than she ..”   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alice in Wonderland Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "r = urlopen(\"http://www.gutenberg.org/files/11/11.txt\")\n",
    "fin= r.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\\r\\n\",\n",
       " b'\\r\\n',\n",
       " b'This eBook is for the use of anyone anywhere at no cost and with\\r\\n',\n",
       " b'almost no restrictions whatsoever.  You may copy it, give it away or\\r\\n',\n",
       " b're-use it under the terms of the Project Gutenberg License included\\r\\n',\n",
       " b'with this eBook or online at www.gutenberg.org\\r\\n',\n",
       " b'\\r\\n',\n",
       " b'\\r\\n',\n",
       " b\"Title: Alice's Adventures in Wonderland\\r\\n\",\n",
       " b'\\r\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white space 제거, 소문자 통일, binary 를 string type 으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"project gutenberg's alice's adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alice's adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 [last updated: december 20, 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pi\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lookup table 작성\n",
    "\n",
    "- text 중에 포함된 character 들을 이용하여 charactet-to-index, index-to-character 변환 table 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(nb_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 및 label data 작성\n",
    "\n",
    "- 10 개의 연속된 character sequence 를 input 으로 하고, 다음에 오는 character 를 label 로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161793 161793\n"
     ]
    }
   ],
   "source": [
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_data = []\n",
    "label_data = []\n",
    "\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_data.append(text[i:i + SEQLEN])\n",
    "    label_data.append(text[i+SEQLEN])\n",
    "    \n",
    "print(len(input_data), len(label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gu',\n",
       " 'roject gut',\n",
       " 'oject gute',\n",
       " 'ject guten',\n",
       " 'ect gutenb',\n",
       " 'ct gutenbe',\n",
       " 't gutenber',\n",
       " ' gutenberg',\n",
       " \"gutenberg'\",\n",
       " \"utenberg's\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'e', 'n', 'b', 'e', 'r', 'g', \"'\", 's', ' ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize input data\n",
    "\n",
    "\n",
    "input data 의 shape : (data_size, times_step, features)  \n",
    "\n",
    "output data 의 shape : (data_size, features)\n",
    "\n",
    "**One-hot encodeing** \n",
    "\n",
    "10 X 57\n",
    "\n",
    "'project gu' ==>  char2index['p'] : 36,  char2index['r'] : 45, char2index['o'] : 49\n",
    "\n",
    "p: [0., 0., 0,,,,,., 0., 0., 0.,0., 0., 0., 0., 1., 0., 0., 0., 0., ,,,,,,,,,,,,,., 0., 0., 0., 0.]  \n",
    "r: [0., 0., 0.,.,,,,,0., 0., 0., 0.,0., 0., 0., 0., ,,., 0., 0., 1., 0., ,,,,,,,,,,,,,., 0., 0., 0.]  \n",
    "0: [0., 0., 0.,.,,,,,0.,0.,0., 0,,,,,,,, 0., 0., 0. 0., 0., 0., 1., 0., ,,,,,,,,,,,,,., 0., 0., 0.]\n",
    "\n",
    "label ==>  char2index['t'] : 1   \n",
    "\n",
    "1X57\n",
    "\n",
    "t: [0., 1., 0.,.,,,,,0.,0.,0., 0,,,,,,,, 0., 0., 0. 0., 0., 0., ., 0., ,,,,,,,,,,,,,., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project gu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161793, 10, 57)\n",
      "(161793, 57)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(input_data), SEQLEN, nb_chars))\n",
    "y = np.zeros((len(label_data), nb_chars))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, ch in enumerate(input_data[0]):\n",
    "    #print(j, ch)\n",
    "    X[0, j, char2index[ch]] = 1\n",
    "    #print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161793, 10, 57) (161793, 57)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(input_data), SEQLEN, nb_chars))\n",
    "y = np.zeros((len(label_data), nb_chars))\n",
    "\n",
    "for i, input_chars in enumerate(input_data):\n",
    "    for j, ch in enumerate(input_chars):\n",
    "        X[i, j, char2index[ch]] = 1              \n",
    "    y[i, char2index[label_data[i]]] = 1\n",
    "    \n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(SEQLEN)\n",
    "print(nb_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trimu\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\trimu\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(256, input_shape=(SEQLEN, nb_chars)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trimu\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "161793/161793 [==============================] - 33s 207us/sample - loss: 2.3783\n",
      "Epoch 2/20\n",
      " 78080/161793 [=============>................] - ETA: 16s - loss: 2.1450"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-858afe7c1035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed 로부터 의미있는 문장 생성하는지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[np.argmax(model.predict(X[0:1, :]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = np.zeros((1, 10, 57))\n",
    "\n",
    "for i, ch in enumerate(\"what is th\"):\n",
    "    Xtest[0, i, char2index[ch]] = 1\n",
    "\n",
    "pred = model.predict(Xtest)          # next character\n",
    "index2char[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed :  e to measu\n"
     ]
    }
   ],
   "source": [
    "# select ramdom seed words\n",
    "test_idx = np.random.randint(len(input_data))\n",
    "test_chars = input_data[test_idx]\n",
    "    \n",
    "print(\"Generating from seed : \", test_chars, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sed to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the d"
     ]
    }
   ],
   "source": [
    "# generate sentence from the seed words\n",
    "for _ in range(1000):\n",
    "    # one-hot encoding (10 X 57)\n",
    "    Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "\n",
    "    for i, ch in enumerate(test_chars):\n",
    "        Xtest[0, i, char2index[ch]] = 1\n",
    "\n",
    "    pred = model.predict(Xtest)      # next character\n",
    "\n",
    "    ypred_ch = index2char[np.argmax(pred)]\n",
    "\n",
    "    print(ypred_ch, end=\"\")\n",
    "    #shift one character\n",
    "    test_chars = test_chars[1:] + ypred_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
